{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Retention\n",
    "\n",
    "The purpose of this project is to determine if there is a model that can determine what factors may lead to a customer leaving a bank service, using customer behavior as a predictive metric. We will build a model that aims to maximize F1 score, with a minimum of 0.59. Additionally, we will compare the AUC-ROC with this F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# for data prep\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# for model creation\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# for model checking\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things to do before we work with the data. We could rename the columns if we wanted to, but due to the format we would need to manually rename them, so we will not do that. What we should try and figure out, then, is the missing values in the \"tenure\" column.\n",
    "\n",
    "According to our dataset, the tenure value is the period of maturation for a fixed deposit. The null values likely are for people who do not have tenure, whereas values of 0 are ones where they have a newly acquired one. For the purposes of analysis, it should be fine to fill out null values in the tenure column with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values\n",
    "\n",
    "data['Tenure'] = data['Tenure'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we work on the data preparation, let's also take a look at the balance of our target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 80% of our users have not exited. We will need to take this in mind and investigate the imbalance later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Next, we should identify our features and target. We know that our target is the \"Exited\" column. The features, then are ones that we should choose to be as relevant as possible.\n",
    "\n",
    "Row number and surname are both somewhat arbitrary identifiers so they are probably not necessary to keep. CustomerID, however, could be a relevant predictor. If, for instance, there are a large amount of customers who signed up in a period who have all exited, that might indicate something. It is unlikely to result in being relevant, but should not cause much issue leaving it in. All the other features are also likely predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target and features\n",
    "\n",
    "target = data['Exited']\n",
    "features = data.drop(['RowNumber', 'Surname', 'Exited'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we split into training, validation, and test set (we will use 60% of the data to the training set, with 20% for a validation set and 20% for test set) now would be a good time to make our features into numeric dummy variables.\n",
    "\n",
    "There are two non-numeric columns: country and gender. The data only contains three countries: Germany, Spain and France. Thus, in both of these columns we can drop one of them to prevent the dummies from influencing our model more than necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies\n",
    "\n",
    "features_ohe = pd.get_dummies(features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test set\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_ohe, target,\n",
    "    test_size=0.20, shuffle = True, random_state = 8)\n",
    "\n",
    "# split the training set into a validation set\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, \n",
    "    test_size=0.25, random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features training: (6000, 12)\n",
      "Target training: (6000,) \n",
      "\n",
      "Features validation: (2000, 12)\n",
      "Target validation: (2000,) \n",
      "\n",
      "Features test: (2000, 12)\n",
      "Target test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of each set\n",
    "\n",
    "print(\"Features training:\", features_train.shape)\n",
    "print(\"Target training:\", target_train.shape, \"\\n\")\n",
    "\n",
    "print(\"Features validation:\", features_valid.shape)\n",
    "print(\"Target validation:\", target_valid.shape, \"\\n\")\n",
    "\n",
    "print(\"Features test:\", features_test.shape)\n",
    "print(\"Target test:\", target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also are different scales for our numerical variables, which likely will result in errors of the model's judgment. Before we build a model, we should deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76/1664466759.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_test[numeric] = scaler.transform(features_test[numeric])\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# scale numeric variables\n",
    "\n",
    "numeric = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test\n",
    "\n",
    "First, we should look at our options between a decision tree, random forest, or logistic model to get our prediction.\n",
    "\n",
    "We also will initialize a single function that prints out a variety of the metrics we're interested in seeing. We will likely want to see each of them for multiple models, so making them a single function will clean up our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checking function\n",
    "\n",
    "def model_metrics(target, predicted):\n",
    "    print(\"Accuracy:\", accuracy_score(target, predicted))\n",
    "    print(\"Recall:\", recall_score(target, predicted))\n",
    "    print(\"Precision:\", precision_score(target, predicted))\n",
    "    print(\"F1:\", f1_score(target, predicted))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7945\n",
      "Recall: 0.5125628140703518\n",
      "Precision: 0.4845605700712589\n",
      "F1: 0.4981684981684981\n",
      "Confusion Matrix:\n",
      " [[1385  217]\n",
      " [ 194  204]]\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n",
      "Recall: 0.4648241206030151\n",
      "Precision: 0.7459677419354839\n",
      "F1: 0.5727554179566563\n",
      "Confusion Matrix:\n",
      " [[1539   63]\n",
      " [ 213  185]]\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "model = RandomForestClassifier(random_state = 12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8155\n",
      "Recall: 0.21608040201005024\n",
      "Precision: 0.6013986013986014\n",
      "F1: 0.31792975970425136\n",
      "Confusion Matrix:\n",
      " [[1545   57]\n",
      " [ 312   86]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "\n",
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for a quick test, we performed a really simple decision tree and random forest classifier, as a means to get a benchmark on the model without tuning any sort of complicated factors. We have scores below our desired threshold for all of our metrics. From our confusion matrices, we see that there seems to be a higher likelihood of finding a false negative, possibly because most of our data are negative results.\n",
    "\n",
    "The random forest classifier seems like it is far more likely to influence the model, with it having a wide swing causing high precision, but the F1 score did not noticeably change. It's very close to our desired 0.59 result already. We can see that the random forest is more likely to result in false negatives, and the decision tree model is more skewed towards false positives.\n",
    "\n",
    "Overall, the random forest model shows the most promise, with the highest level of accuracy, as well as the most clear path on what we should do, since there are very few false positives in that model. Thus, for the remainder of the project we will focus on the random forest.\n",
    "\n",
    "To get an idea of the model on a basic level, we will also create a simple PR curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set model to random forest\n",
    "\n",
    "model = RandomForestClassifier(random_state = 12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# check PR curve\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    target_valid, probabilities_valid[:, 1]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that we were expecting amazing results from such a simple model, but this curve does seem to show that the model is already looking pretty good. We can try to make it even more robust, which is necessary as the random forest did not give us our desired F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model improvement\n",
    "\n",
    "Seeing the results from the Random Forest model shows that will likely be our best choice for this problem. Now we need to tweak the model to get our desired accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that balancing our class weight did not have much impact on our data. It is slightly more accurate (0.001 more) but the recall is lower and so that causes the F1 score to be lower than leaving them unbalanced.\n",
    "\n",
    "We can also try tuning some hyperparameters and see what impact that has on pushing our F1 score up. We will start by seeing a minimum sample split tuning. However, before we do anything involving tuning our model, we should try and get our data in the most useful state it can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n"
     ]
    }
   ],
   "source": [
    "# create upsample function\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state = 12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# upsample data\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 10\n",
    ")\n",
    "\n",
    "# create upsampled model\n",
    "\n",
    "model = RandomForestClassifier(random_state = 12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5535\n",
      "Recall: 0.9472361809045227\n",
      "Precision: 0.3018414731785428\n",
      "F1: 0.4578020643594414\n",
      "Confusion Matrix:\n",
      " [[730 872]\n",
      " [ 21 377]]\n"
     ]
    }
   ],
   "source": [
    "# create downsample function\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state = 12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state = 12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state = 12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# downsample data\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.1\n",
    ")\n",
    "\n",
    "# create downsampled model\n",
    "\n",
    "model = RandomForestClassifier(random_state = 12345)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upsampling is very promising. It increased our F1 slightly by simply going to 10 observations. In comparison, the downsampling, while it did reduce the issue with our false negatives, also ended up dramatically raising our false positives so our F1 score took a massive hit. It seems that upsampling is the way to go.\n",
    "\n",
    "Firstly, we can aim to get a larger upsample as that will lead to am improvement in our F1 score, but it will have diminishing returns and if we perform too many upsamples then it could become counterproductive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8425\n",
      "Recall: 0.4899497487437186\n",
      "Precision: 0.6351791530944625\n",
      "F1: 0.5531914893617021\n",
      "Confusion Matrix:\n",
      " [[1490  112]\n",
      " [ 203  195]]\n"
     ]
    }
   ],
   "source": [
    "# set model using upsampled data\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 100\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(random_state = 12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our 10 upsamples did reduce our precision more than they increased our recall. As we take more upsamples we lose precision faster than we gain recall. We will stick to upsampling just 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we might wish to look at adjusting our thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.00 | Precision = 0.208, Recall = 0.997, F1 = 0.344\n",
      "Threshold = 0.02 | Precision = 0.231, Recall = 0.992, F1 = 0.375\n",
      "Threshold = 0.04 | Precision = 0.256, Recall = 0.982, F1 = 0.406\n",
      "Threshold = 0.06 | Precision = 0.279, Recall = 0.970, F1 = 0.433\n",
      "Threshold = 0.08 | Precision = 0.301, Recall = 0.962, F1 = 0.458\n",
      "Threshold = 0.10 | Precision = 0.318, Recall = 0.935, F1 = 0.474\n",
      "Threshold = 0.12 | Precision = 0.337, Recall = 0.915, F1 = 0.492\n",
      "Threshold = 0.14 | Precision = 0.349, Recall = 0.884, F1 = 0.501\n",
      "Threshold = 0.16 | Precision = 0.365, Recall = 0.859, F1 = 0.512\n",
      "Threshold = 0.18 | Precision = 0.381, Recall = 0.837, F1 = 0.524\n",
      "Threshold = 0.20 | Precision = 0.398, Recall = 0.819, F1 = 0.535\n",
      "Threshold = 0.22 | Precision = 0.418, Recall = 0.799, F1 = 0.549\n",
      "Threshold = 0.24 | Precision = 0.435, Recall = 0.779, F1 = 0.559\n",
      "Threshold = 0.26 | Precision = 0.457, Recall = 0.759, F1 = 0.570\n",
      "Threshold = 0.28 | Precision = 0.473, Recall = 0.731, F1 = 0.575\n",
      "Threshold = 0.30 | Precision = 0.489, Recall = 0.709, F1 = 0.578\n",
      "Threshold = 0.32 | Precision = 0.509, Recall = 0.688, F1 = 0.585\n",
      "Threshold = 0.34 | Precision = 0.535, Recall = 0.658, F1 = 0.590\n",
      "Threshold = 0.36 | Precision = 0.557, Recall = 0.646, F1 = 0.598\n",
      "Threshold = 0.38 | Precision = 0.570, Recall = 0.626, F1 = 0.596\n",
      "Threshold = 0.40 | Precision = 0.582, Recall = 0.601, F1 = 0.591\n",
      "Threshold = 0.42 | Precision = 0.596, Recall = 0.583, F1 = 0.590\n",
      "Threshold = 0.44 | Precision = 0.609, Recall = 0.555, F1 = 0.581\n",
      "Threshold = 0.46 | Precision = 0.616, Recall = 0.545, F1 = 0.579\n",
      "Threshold = 0.48 | Precision = 0.630, Recall = 0.525, F1 = 0.573\n",
      "Threshold = 0.50 | Precision = 0.635, Recall = 0.490, F1 = 0.553\n",
      "Threshold = 0.52 | Precision = 0.655, Recall = 0.472, F1 = 0.549\n",
      "Threshold = 0.54 | Precision = 0.683, Recall = 0.455, F1 = 0.546\n",
      "Threshold = 0.56 | Precision = 0.708, Recall = 0.432, F1 = 0.537\n",
      "Threshold = 0.58 | Precision = 0.725, Recall = 0.425, F1 = 0.536\n",
      "Threshold = 0.60 | Precision = 0.733, Recall = 0.407, F1 = 0.523\n",
      "Threshold = 0.62 | Precision = 0.739, Recall = 0.377, F1 = 0.499\n",
      "Threshold = 0.64 | Precision = 0.753, Recall = 0.359, F1 = 0.486\n",
      "Threshold = 0.66 | Precision = 0.758, Recall = 0.347, F1 = 0.476\n",
      "Threshold = 0.68 | Precision = 0.762, Recall = 0.314, F1 = 0.445\n"
     ]
    }
   ],
   "source": [
    "# check threshold adjustments\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_valid, predicted_valid)\n",
    "    recall = recall_score(target_valid, predicted_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "    print('Threshold = {:.2f} | Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3f}'.format(\n",
    "                threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that raising our threshold does slowly raise our F1 score, as the recall and precision become more balanced. In between a threshold of 0.36, we see a maximized F1 score of 0.598 - this is actually good enough for our objective. We also see that it will be maximized at that point, as once we pass it, our recall drops and the F1 score begins to decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8345\n",
      "Recall: 0.6005025125628141\n",
      "Precision: 0.5815085158150851\n",
      "F1: 0.5908529048207664\n",
      "Confusion Matrix:\n",
      " [[1430  172]\n",
      " [ 159  239]]\n"
     ]
    }
   ],
   "source": [
    "# set predictions with the threshold\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "predicted_valid = probabilities_one_valid > 0.4\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a handle on how well our model is doing, let's make a ROC curve to find out our false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4w0lEQVR4nO3dd3xUZfb48c9JJyEk9BZ67y2CCCoWEBXBggiKbXVdu67lt+66X9u6bnF1V3fdVVTEhmJZBQXBLopI71V6AgkEQkJIT+b8/rgXySKEgWRyZybn/XrNK/feuXPncEnmzH2e+5xHVBVjjDHmWCK8DsAYY0xws0RhjDGmUpYojDHGVMoShTHGmEpZojDGGFMpSxTGGGMqZYnCGGNMpSxRmLAjIttEpFBEDopIpohMEZG6R+xzmoh8KSJ5IpIrIh+JSPcj9qknIv8QkR3usTa7641q9l9kjLcsUZhwdZGq1gX6Av2A3x56QkQGA58C04EWQDtgBTBPRNq7+8QAXwA9gJFAPWAwsA8YGKigRSQqUMc25mRZojBhTVUzgTk4CeOQvwKvqeozqpqnqtmq+nvgB+ARd59rgNbAJaq6VlV9qrpHVf+gqrOO9l4i0kNEPhORbBHZLSK/c7dPEZHHK+w3TETSK6xvE5HfiMhKIN9dfu+IYz8jIs+6y0ki8rKIZIjIThF5XEQiq3amjDk2SxQmrIlICnA+sMldjwdOA949yu7vAMPd5XOB2ap60M/3SQQ+B2bjXKV0xLki8dcE4EIgGXgbuMA9Jm4SGAdMdfedApS579EPGAHceALvZcwJsURhwtWHIpIHpAF7gIfd7Q1wfu8zjvKaDOBQ/0PDY+xzLKOATFV9SlWL3CuVBSfw+mdVNU1VC1V1O7AUuMR97mygQFV/EJGmwAXA3aqar6p7gL8D40/gvYw5IZYoTLi6WFUTgWFAVw4ngP2AD2h+lNc0B/a6y/uOsc+xtAI2n1SkjrQj1qfiXGUAXMnhq4k2QDSQISI5IpIDvAA0qcJ7G1MpSxQmrKnqNzhNNX9z1/OB+cDlR9l9HIebiz4HzhORBD/fKg1of4zn8oH4CuvNjhbqEevvAsPcprNLOJwo0oBioJGqJruPeqraw884jTlhlihMbfAPYLiI9HHXHwCuFZE7RSRRROq7nc2DgUfdfV7H+VB+X0S6ikiEiDQUkd+JyAVHeY+PgeYicreIxLrHHeQ+txynz6GBiDQD7j5ewKqaBXwNvAJsVdV17vYMnDu2nnJv340QkQ4icuaJnhRj/GWJwoQ990P3NeAhd/074DzgUpx+iO04ncJDVfVHd59inA7t9cBnwAFgIU4T1s/6HlQ1D6cj/CIgE/gROMt9+nWc22+34XzIT/Mz9KluDFOP2H4NEAOsxWlKe48TayYz5oSITVxkjDGmMnZFYYwxplIBSxQiMllE9ojI6mM8LyLyrIhsEpGVItI/ULEYY4w5eYG8opiCU/rgWM4HOrmPm4D/BDAWY4wxJylgiUJV5wLZlewyBqeMgqrqD0CyiFiHnDHGBBkvC5C15H8HGaW72342GlZEbsK56iAhIWFA165dayRAY0ztUe5T56HOT98R6z9/DvRnw1+qn09BVVEFH87PE9GSvdSTAlZklOxV1cYnE0NIVKpU1UnAJIDU1FRdvHixxxEZY4JVabmP/QUlZOeXkH2whGx3ed9Bd1tBCfvzS8gpKOVAUSkHCkvJKy6r9AM4SqB+bBRJ8dHUi3MfdaKIjgz8/UAxkRHERkcQGxVJbFQEMVERxEY56z8tu8//tG+ku190JI3Wv05MUTbJFzy0/WRj8DJR7MQpe3BIirvNGFPLqSplPqW4zEdxaTkFJeXsLyhhn/vhX3F5X37JT4lh38FiDhSVHfO4yfHRNIiPoUFCDC2S4+gal0i9OtHOIy6KenWiSapzOBEkuc/VjYkiIkJq8AxUwYFd8PE90PNS6D0Omt/mPvHQSR/Sy0QxA7hdRN4GBgG57qhTY0wIUVXyisvIyS8lp7CE/QWl5Ljf2vcXlJJbWEpxWTnFpT6K3J/FZT6Ky8opKnV+Ognhf7f5jtPEEh0p1Hc/9BvWjaFHi3o0TIihQUIsDerG/JQQGtaNoX58DPXjo4mqgSsAz6jC0lfh0/+D8lLoPKLaDh2wRCEib+EUZGvk1t5/GKeYGar6PDALpwrmJqAAuD5QsRhjTky5T8nKK2ZnTgE7c4rIyCkk2/3m/lMicH/mFJRSVsmnemJsFHExkcRVaD6JjYogLjqSurFRxEZVeC768HOHmldio531BvEx1E+IcZJB3RgSY6MQCZFv+YGWvQVm3AnbvoW2p8PoZ6HBsUqPnbiAJQpVnXCc5xW4rbJ9jDGBUVhSzs6cQnblFB7+ud9dzi0kI6foZx/+sVER1I+PITk+muT4aDo1qUuy+0398HZn/dDPpDph/i0+WOxeCxkr4KJnoP+1UM0JNCQ6s40x/8vnU3IKS8nKKyYrr5gDRaXkF5c5j5Lyn5YPFpdTUFLGweIyCtzte/KKyc4v+Z/jRQg0T6pDi+Q4+reuT8vedWiRXIeW9evQMtlZrhtrHxdB5VBy6DsBuo2CNqdBfIOAvJX9zxsTRFSVzANFpGUXukmgiKyDxT8lhEPL+w6WVNrcExUhJMRGkRAT6fyMjSIhNpKGCfH0b1OflsmHE0DL+nVomhhr3/xDRVkJfPuU86jbBHpcAtFxAUsSYInCGM/kFpaycXce6zPz2JB5gI2ZB1mfeeBnd+1ERgiN6sbQODGWxnVj6d683k/LjRPjaFQ3hqT4aBJiDieEmMgIa78PR+mLYfrtkLUOel8B5/3JSRIBZonCmBqSll3AO4vTWJmey8bdeWTkFv30XGJsFF2aJXJRnxZ0aZZI24YJNKnnJIP68TGhc2umCZwDu2DySOcq4sp3oPN5NfbWliiMCbClO/bz8rdb+WR1BiJC56aJnNq+IV2aJdKlaSJdmiXSPCnOrgDM0e3dBI06Qr0WcPkr0O5MiKtXoyFYojAmAMrKfXy6djcvfbuFpTtySIyL4pdntOfawW1pkVzH6/BMKCjMgc8egqWvwXUzoe0Q6HaRJ6FYojCmGuUVlTJtURpTvt9G+v5C2jSM55GLunN5aisS7K4h46/1s2DmPXBwNwy5E1p6OwuD/eYaU0Wqyta9+UxdsIO3F6VxsLiMgW0b8H+junNut6ZEWv+CORHTb4dlr0OTHjB+qudJAixRGHPCcgpKWJGey/IdOaxIz2FFWg778kuIjBAu7NWcG4a2o0+rZK/DNKHkUEVCEWjRD5Jbw5C7ISrG07AOsURhTCWKy8pZl5HH8h37WZ6Ww4r0XLbuzQecv+mOjetydtcm9G2dzFldmlj/gzlxuenw8a+h52XQZzyccoPXEf2MJQpjjnCgqJQv1+3hk9UZfL0hi+IyHwCNE2Pp2yqZsQNS6NcqmV4pSSTGRXscrQlZPh8smQyfPQJaDl1HeR3RMVmiMAanOemztbuZvTqTb3/cS0m5jyaJsVxxSitObd+Qvq2S7RZWU332bYYZd8D2edB+mFOjqX5br6M6JksUplbbsa+AP89ex6drdlPmU1om1+HqwW24oFcz+rWqbwPdTGBkrYfdq2HMc9D3qmov4lfdLFGYWqmwpJx/f72JF+ZuITpCuGFoOy7o1ZzeKUl21WACI3OV8+h7JXS9EO5aAXXqex2VXyxRmFpFVZm1KpM/zlzLrtwiLu7bgt9e0I2m9QJfL8fUUmXFMPdJ+O7vULcZ9LjUqc8UIkkCLFGYWmTj7jwenr6G+Vv20a15Pf4xvh8D2wWu4qYxpC10xkXs3QB9JsB5T9RIEb/qZonChL2lO/bzyrxtzFqVQd3YKP4wpgcTBra2stomsA7sglcugLpN4ar3oNNwryM6aZYoTFgqLffxyepMJn+3leVpOSTGRvGLIW25ZVhHGiQExyAmE6ayNkDjLm4RvynQ/kyITfQ6qiqxRGHCSk5BCW8u2MHr87eTeaCIdo0SeHR0Dy4bkGIztJnAKtwPc34Py9+A6z9xZpzrFrxjI06E/eWYsLArp5CXvt3KWwt3UFhaztCOjXji0p4M69zEbnE1gbfuI5h5L+TvhaH3QAvv6zNVJ0sUJqT9uDuP57/ZwvTlOwEY3acFN53Znq7NarZev6nFPrzNuYpo1suZUKhFX68jqnaWKEzIUVXmb9nH5O+28fm63dSJjmTiqW248fR2pNSP9zo8UxtULOKXkgoN28Npd0JkeJZ0sURhQkZOQQnvLUln6oIdbNmbT3J8NHed04lrT2trHdSm5uTsgI/uhl6XQ98JkHq91xEFnCUKE9RUleVpObzxww4+XrmL4jIf/Vsn89Tlfbiwd3PioiO9DtHUFj4fLH4ZPn/EuaLocbHXEdUYSxQm6JSU+ViyfT/fbcrii3V7WJ+ZR0JMJGMHpHDVoDZ0b2H9D6aG7f3RKeK3Yz50OBtG/QPqt/E6qhpjicIEhU17DvLNxiy++zGLH7ZkU1haTmSE0LdVMn+4uCeX9Gtpt7ca7+z9Efasg4v/44ywrmX1wOwvz3hqT14Rf5q1ng+WOXcttW+UwOWpKQzt2IhTOzSkns33YLySscIp4tdvInS9wC3il+x1VJ6wRGE8UVbu47X52/n7ZxspLvNx+1kdmTCoNS1thjjjtdIi+OYvMO8ZZ3R1z7FuEb9kryPzjCUKU+MWb8vm9x+uZn1mHmd0bsyjo3vQrlGC12EZAzt+cIr47fsR+k6E8x4PySJ+1c0Shakxa3bl8u+vNzNzZQYtkuJ4fmJ/zuvRzOZ/MMHhwC6YMgrqNYeJ/4WO53gdUdCwRGECbtG2bJ77ahNfb8iibmwUt5/VkVvP6kB8jP36mSCwZz006eo0M13xOrQ9HWLreh1VULG/VBMQuw8U8dna3Xy4bCeLt++nQUIM943ozNWD25JUxzqoTRAoyIY5D8KKqXDdLGg7BLqc73VUQckShak2m7MO8uma3cxZk8nytBwA2jaM5+GLujP+lNbUibHBcSZIrJ0OM++Dwmw4/T5oOcDriIKaJQpTJarK95v38c8vf+SHLdkA9GqZxH0jOjOiRzM6NalrfRAmuHxwi3MV0bwPTHwfmvf2OqKgZ4nCnBRV5asNe/jnl5tYtiOHpvVi+d0FXRnVuwUt7BZXE2wqFvFrNRAad4bBd0CkfQT6I6BnSURGAs8AkcBLqvrnI55vDbwKJLv7PKCqswIZk6maotJyPl+3m39/tZm1GQdIqV+Hxy/uydgBKVZ3yQSn/dvgo7ug9xXQ98paUcSvugUsUYhIJPAcMBxIBxaJyAxVXVtht98D76jqf0SkOzALaBuomMzJKSgp45sNWcxancmX63aTX1JO+0YJ/O3yPozp24Jom3vaBCNfOSx8Eb54FCQCeo3zOqKQFcgrioHAJlXdAiAibwNjgIqJQoFDFd6SgF0BjMecoF05hfzpk/V8tjaTolIfDRNiGN23Jef3bMaQjo2ItJnjTLDK2uAMnEtfCB2Hw6i/Q3Irr6MKWYFMFC2BtArr6cCgI/Z5BPhURO4AEoBzj3YgEbkJuAmgdevW1R6o+V+qygfLdvLwjDWU+5Rxqa04v2dzTmlbnyi7ejChIHuLM7r6kknQe1ytK+JX3bzuyZkATFHVp0RkMPC6iPRUVV/FnVR1EjAJIDU1VT2Is9bYd7CYBz9Yzew1mZzStj5PXd6X1g1t1jgTAnYtg8zV0P9qZzzEXSshzkrSV4dAJoqdQMVrvRR3W0U3ACMBVHW+iMQBjYA9AYzLHEFVWbojh+nLdzJjxS4Kisv57fldufH09ta8ZIJfaSF8/Wf4/p+Q1NKZeS46zpJENQpkolgEdBKRdjgJYjxw5RH77ADOAaaISDcgDsgKYEymgh935/HRil18uHwXO7ILiI2K4NzuTbnj7I50bWZ/ZCYEbJvnTCiUvRn6XQ0jrIhfIAQsUahqmYjcDszBufV1sqquEZHHgMWqOgO4F3hRRH6N07F9napa01KAqCrrMvKYvTqDWasz2bTnIBECp3VoxJ3ndOK8Hk1JtPkfTKg4sAteGw31WsI106H9MK8jClsSap/LqampunjxYq/DCCk+n/Lq/G28+v02tu0rIEJgYLsGXNCrOSN7NKNJPfsGZkLI7jXQtIezvGE2tDsdYqxM/fGIyBJVTT2Z13rdmW0CLC27gPveXcGCrdkMbNeAm87owIgeTWlUN9br0Iw5Mfn7YM5vYeW0CkX8RnodVa1giSJMqSrvLk7nsY+dYSt/HdubywekWN0lE3pUYc0HMOt+KMqBMx+AlJP6YmxOkiWKMLQu4wBPzFrHtz/uZVC7Bvzt8j60amC3uJoQ9cHNsPJtaNEPxsw43OxkaowlijCSkVvIU59u5P2l6dSLi+bhi7pz7eC2RNgtribUVCzi13aIkxxOvdWK+HnEznqYmLpgB499vAafD355entuG9aRpHi7g8mEoOyt8NGdThG/fhOh/zVeR1TrWaIIA7NXZ/Dgh6sY2rERT1zSy5qZTGjylcOCF+DLP4BEQp8JXkdkXJYoQtyS7fu56+3l9G2VzIvXpFqpbxOa9qyH6bfBzsXQ6TyniF9SS6+jMi5LFCFs6958bnx1Ec2T4njJkoQJZTnbYf9WuOxl6HmZFfELMpYoQkhpuY8Plu5kbcYBftyTx6r0XKIiI5hy/UAa2rgIE2p2LoHMVTDgOuh8Hty1AmITvY7KHIUlihDy9Gcb+c/Xm0mIiaRjk7oM796MXwxtS9tGNirVhJCSAvjqj/DDvyGpFfQe79RnsiQRtCxRhIgNmXm8OHcLl/VP4W+X97aBcyY0bf3WKeK3fysMuB6GP2pF/EKAJYoQ4PMpD36wisS4KB68sJslCROacnfC6xc7VxHXfgTtzvA6IuMnSxQh4J3FaSzevp8nx/amQUKM1+EYc2IyV0GzXs5dTOPfgrZDIcZu4Q4lliiClKqyaNt+3l+SzvQVOxnUrgFjB6R4HZYx/svfC5/8Bla/B9fNdBJE5xFeR2VOgiWKIHOwuIzJ323l/aXpbN9XQHxMJKN6t+DeEZ2tycmEBlVY/T588v+g6AAM+x2kDPQ6KlMFliiCiM+n3PnWMr5cv4fTOjTkrnM6MbJnM+Jj7L/JhJD/3gSr3oGWqTDmX9Ckm9cRmSry+xNIROJVtSCQwdR2//lmM1+u38NjY3pwzeC2XodjjP98PmeQnIgzkVCLvjDoZoiwQaDhIOJ4O4jIaSKyFljvrvcRkX8HPLJaZuHWbJ76dAMX9WnB1ae28TocY/y3b7MzJemyN5z1/tfA4NssSYSR4yYK4O/AecA+AFVdAdh9bdXI51Me/WgNLZLr8KdLe1lfhAkN5WUw71n4z2mQsRIi7Y68cOVX05Oqph3x4VUemHBqp1mrM1iz6wBPj+tD3VjrjzAhYPdamH4r7FoGXS6EC5+Ces29jsoEiD+fSmkichqgIhIN3AWsC2xYtUdZuY+nP91I56Z1GdPXqmWaEJGbDjlpMHYy9LjUiviFOX+anm4GbgNaAjuBvsCtAYypVpm2OI0te/O5b0QXIm0mOhPM0hfD4lec5c4jnCJ+Vum1VvDniqKLql5VcYOIDAHmBSak8FdW7uPzdbt5bf52vt+8j/6tkxnevanXYRlzdCX58KVbxK9+W+h7JUTFQmxdryMzNcSfRPFPoL8f28xxZOUVM23RDt5csIOM3CJaJMVx/3lduGpQa+vANsFpyzfOtKT7t0HqDXDuI06SMLXKMROFiAwGTgMai8g9FZ6qB9h9byeg3KdM+X4bf5uzgcLScoZ2bMQjo3twTtcmREX60/pnjAdyd8Ibl0JyG7huFrQd4nVExiOVXVHEAHXdfSoWij8AjA1kUOFkeVoOj360hmU7cjirS2MevLA7HZvYJbsJYhkroHkfp4jfhGlOgoiu43VUxkPHTBSq+g3wjYhMUdXtNRhTWPhi3W6e+2oTS3fkkBwfzT+u6MuYvi2sickEr4N7nPpMaz44XMSv07leR2WCgD99FAUi8iTQA/hphhFVPTtgUYW49ZkHuOHVxbRpGM/DF3Vn7IAUEuOivQ7LmKNThZXvwOzfOB3XZ/8eWg3yOioTRPxJFG8C04BROLfKXgtkBTKoUDdp7hbiYyKZftsQkuNttKoJcu/f4FR7TRnoFPFr3MXriEyQ8SdRNFTVl0XkrgrNUYsCHVio+nF3HjOW72LiqW0sSZjgVbGIX4eznSQx8JdWn8kclT+JotT9mSEiFwK7gAaBCyl0fbZ2N/dMW05iXBS/PKO91+EYc3R7Nzm3vPYZ7xTw6zfR64hMkPMnUTwuIknAvTjjJ+oBdwcyqFA0e3UGN7+xlF4tk/jPxP60TLa7REyQKS+D+f+Cr//kjIWIst9R45/jJgpV/dhdzAXOgp9GZhtXSZmPJ2atp2uzRN69eTBx0Xb5boJM5mqYfhtkLIeuo5wifonNvI7KhIjKBtxFAuNwajzNVtXVIjIK+B1QB+hXMyEGv7cX7WBHdgGvXH+KJQkTnA7sggM74fJXofsYq89kTkhlw4JfBm4EGgLPisgbwN+Av6qqX0lCREaKyAYR2SQiDxxjn3EislZE1ojI1BP9B3htT14Rf/9sI4PaNWBY58Zeh2PMYTsWwKKXneVDRfx6XGxJwpywypqeUoHequoTkTggE+igqvv8ObB7RfIcMBxIBxaJyAxVXVthn07Ab4EhqrpfRJqc7D/EC6rKA++voqCknD9e0tMG05ngUHwQvvwDLHgBGrRzOqujYiEmwevITIiqLFGUqKoPQFWLRGSLv0nCNRDYpKpbAETkbWAMsLbCPr8EnlPV/e777Dmh6D2iqmzOyuf9pel8uX4PD43qTscmicd/oTGBtukL+OhuyE1zbnc95yEr4meqrLJE0VVEVrrLAnRw1wVQVe19nGO3BNIqrKcDRw737AwgIvNwCg0+oqqzjzyQiNwE3ATQunXr47xt4N3+1jJmrswA4NxuTbnutLbeBmQMOJMJTR0H9dvB9Z9Am8FeR2TCRGWJolsNvX8nYBiQAswVkV6qmlNxJ1WdBEwCSE1N1RqI65j2HChi5soMxg5I4Y6zO9K6Qbw1ORlv7VoGLfpBUgpc9S60Pg2i447/OmP8VFlRwKoWAtwJtKqwnuJuqygdWKCqpcBWEdmIkziCduT3nLW7AbjpjPa0aWhtvsZDebvhk/th7fTDRfw6WAk2U/0CORnCIqCTiLQTkRhgPDDjiH0+xLmaQEQa4TRFbQlgTFX2yaoM2jdKoJOVCjdeUYXlU+G5gbBhttMPYUX8TAD5MzL7pKhqmYjcDszB6X+YrKprROQxYLGqznCfGyEia4Fy4P4T7DCvUXM3ZvH95n3cf14Xa24y3nnveqcUeKtTYfQ/oXFnryMyYU5Uj9/kLyJ1gNaquiHwIVUuNTVVFy9eXOPvW1Razsh/zEVEmH336cRG2cA6U4MqFvFbPtW5BfaUGyHCZkg0/hGRJaqaejKvPe5vmYhcBCwHZrvrfUXkyCaksDd53la27SvgD2N6WpIwNStrI7xyPix9zVnveyUMusmShKkx/vymPYIzJiIHQFWXA+0CFlEQKi4r55V52zijc2OGdmrkdTimtigvhbl/g+eHQNZ6GzBnPONXmXFVzT2iTd7TW1Rr2ozlu8jKK+bpcbUqPxovZayE6bdC5iqnNtP5T0JiU6+jMrWUP4lijYhcCUS6JTfuBL4PbFjBw+dTXv5uK12bJTK0o11NmBpycI/zGPc6dB/tdTSmlvOn6ekOnPmyi4GpOOXG7w5gTEHl/aXprM/M4+YzO9idTiawts+HhS86y53OhTuXW5IwQcGfK4quqvog8GCggwk22/bm8+hHa0ltU5/RfVp4HY4JV8V58PmjsOhFaNDBmXUuKhZi4r2OzBjAv0TxlIg0A94Dpqnq6gDHFDT+/vlGAJ6Z0I+ICLuaMAGw6XO3iF86DLoFzv69FfEzQee4TU+qehbOzHZZwAsiskpEfh/wyDy2263pdMUprWxaUxMYuekw9QqIrgO/mAPn/xlibcS/CT5+3Yitqpmq+ixwM86YiocCGVQweH3+dspVuXZwW69DMeFEFdKXOMtJKXDVe/Crb6G1leAwwcufAXfdROQREVkF/BPnjqeUgEfmoe378nlzwXaGd2tK64bWTmyqSV4mTJsIL50N275ztnU4yyq9mqDnTx/FZGAacJ6q7gpwPJ7LLSzl4ufmUVau3HF2J6/DMeFAFZa/CXN+B2XFcO6jTp0mY0LEcROFqtaq2U+mzNvG/oJSPr5jKD1bJnkdjgkH717rlAJvfZpTxK9RR68jMuaEHDNRiMg7qjrObXKqOBLb3xnuQk5eUSkvf7eF4d2bWpIwVeMrB8Spx9T5fGh3Bgz4hdVnMiGpsiuKu9yfo2oikGDw2vztHCgq405rcjJVkbUBpt8O/a6CAddB3wleR2RMlRzz642qZriLt6rq9ooP4NaaCa9mvbcknSEdG9Irxa4mzEkoL4VvnoTnh8K+HyG2ntcRGVMt/LkOHn6UbedXdyBeU1V27i+kZwtLEuYkZKyAScPgq8eh6yi4bRH0vNTrqIypFpX1UdyCc+XQXkRWVngqEZgX6MBqWnZ+CSXlPpol2a2K5iQczIKCfTB+KnS90OtojKlWlfVRTAU+Af4EPFBhe56qZgc0Kg9k5BYB0DzJRmEbP22bB3vWwsBfukX8ljmjrI0JM5U1PamqbgNuA/IqPBCRBoEPrWZ9vm43AB2bWAkFcxxFB+Dje2DKBbDgeWdsBFiSMGHreFcUo4AlOLfHVqyKp0D7AMZVo/YeLObFuVs4v2czSxSmchs/hY/vhrwMGHw7nPU7K+Jnwt4xE4WqjnJ/hvW0bj6f8sTMdRSV+bjvvC5eh2OCWW46vD0BGnaCca9ByknNU29MyPGn1tMQEUlwlyeKyNMi0jrwodWMX7+znP8u28mtwzrQobFdTZgjqELaImc5KQWu/gB+NdeShKlV/Lk99j9AgYj0Ae4FNgOvBzSqGrI56yDTl+/iV2e2557hnb0OxwSbAxnw9pXw8rmHi/i1OwOiYryNy5ga5k+iKFNVBcYA/1LV53BukQ15X7gd2NcMbmvTnJrDVGHJq/DcINj8JYx43Ir4mVrNn+qxeSLyW+Bq4HQRiQCiAxtWYJX7lNmrM3n1++10b17PJiYy/+udq2HdR9BmKIx+Fhp28DoiYzzlT6K4ArgS+IWqZrr9E08GNqzA2bg7j1vfXMqmPQdp3yiB/xvV3euQTDCoWMSv6yjocDb0v86K+BmDf2XGM0XkTeAUERkFLFTV1wIfWvXbkJnH2Oe/Jy46kueu7M/Ins2ItLmwze61MOMO6H+1U8Svz3ivIzImqPhz19M4YCFwOTAOWCAiYwMdWCC89O0WfD7lg1tP48LezS1J1HZlJfD1n+GFM2D/VohL9joiY4KSP01PDwKnqOoeABFpDHwOvBfIwKrbweIyZq7KYHSfFqTUt+lNa71dy+DDW50SHL0uh5F/hoRGXkdlTFDyJ1FEHEoSrn34d7dUUJm1MoOCknIuT23ldSgmGBRkQ1EuTJgGXUZ6HY0xQc2fRDFbROYAb7nrVwCzAhdS9dufX8KL326hQ+ME+rdO9joc45Wtc53+iFNvho7nwB1LIdqqBRtzPP50Zt8vIpcCQ91Nk1T1g8CGVX3Kfcqtby5le3YBL1w9wMZL1EZFufDZQ7BkCjTqDKnXO/WZLEkY45fK5qPoBPwN6ACsAu5T1Z01FVh1+WztbuZv2cdfL+vNWV2aeB2OqWkbPoGPfw0Hd8Npd8AwK+JnzImqrK9hMvAxcBlOBdl/1khE1Wzh1mxioyK4uF9Lr0MxNS03HaZdDXUawI2fOyOsY+xGBmNOVGVNT4mq+qK7vEFEltZEQNVtyY799GmVTExUyPW/m5OhCmkLofWgw0X8Wg2y+kzGVEFln55xItJPRPqLSH+gzhHrxyUiI0Vkg4hsEpEHKtnvMhFREanWkpwZuYWsSs9hcPuG1XlYE6xyd8Jb42HyiApF/E63JGFMFVV2RZEBPF1hPbPCugJnV3ZgEYkEngOGA+nAIhGZoaprj9gvEbgLWHBioR/fp2t241Os2Snc+XywdAp8+hD4yuC8J6D1YK+jMiZsVDZx0VlVPPZAYJOqbgEQkbdxKtCuPWK/PwB/Ae6v4vv9zPeb95JSvw7tGiVU96FNMHnnalj/sVMC/KJnoUFYz7VlTI0LZMN9SyCtwnq6u+0nbhNWK1WdWdmBROQmEVksIouzsrL8enOfT1mwNduancJVeZlzJQHQbbSTIK6ZYUnCmADwrIfXLVf+NM5kSJVS1UmqmqqqqY0bN/br+JuyDpJTUMogSxThJ3O1M5nQ0inOep8rYMC1YGNkjAkIf0Zmn6ydQMV6GSnutkMSgZ7A1+4guGbADBEZraqLq/rm2/bmA9CpiU1vGjbKiuHbp5xHXDLEW20mY2rCcROFOJ/iVwHtVfUxdz6KZqq68DgvXQR0EpF2OAliPM68FgCoai7w01+6iHyNM6ivykkCIH1/IQCtGth982Fh5xKniF/Weug9Hkb+CeIbeB2VMbWCP1cU/wZ8OHc5PQbkAe8Dp1T2IlUtE5HbgTlAJDBZVdeIyGPAYlWdUaXIK39vvt+8j/iYSOrHh/RkfOaQwhwoyYer3oNOw72OxphaxZ9EMUhV+4vIMgBV3S8ift2YrqqzOKKAoKo+dIx9h/lzTH/8sCWbz9ft5vazOlptp1C25RunDPipt7hF/JZY+Q1jPOBPZ3apOyZC4af5KHwBjaqKVu3MAeAXQ+0OmJBUmOPMOPfaaFj8itM3AZYkjPGIP1cUzwIfAE1E5I/AWOD3AY2qitbsOkDzpDgaJNiI3JCzfiZ8fA/k74Ehd8Gw31qCMMZj/pQZf1NElgDnAAJcrKrrAh5ZFWzIzKNb83peh2FOVE4avHMtNO4CE96Cln5VijHGBJg/dz21BgqAjypuU9UdgQysKvKKykiMC+Sdv6baqMKO+dDmNEhuBddMh5RTrD6TMUHEn0/TmTj9EwLEAe2ADUCPAMZ10lbvzGVnTiE3tW7vdSjmeHLSnLkiNn0G182EtkOh7RCvozLGHMGfpqdeFdfdshu3BiyiKvr2x70AXNSnhceRmGPy+WDxy/D5I84Vxfl/tSJ+xgSxE26fUdWlIjIoEMFUh3K3/o81PQWxaRNhw0xofxZc9AzUb+N1RMaYSvjTR3FPhdUIoD+wK2ARmfBUXgYSARER0PNS6HoB9L3K6jMZEwL8GUeRWOERi9NnMSaQQZkwk7kKXjoblrzirPcaC/0mWpIwJkRUekXhDrRLVNX7aigeE05Ki2DukzDvH1CnPtRt6nVExpiTcMxEISJRbr2mkLoNZX1mHnVjo4i0b6veSl8CH94MezdCnyvhvD9aET9jQlRlVxQLcfojlovIDOBdIP/Qk6r63wDHdsK27c1n1qoMfnlGeyIiLFF4qviAc0Ux8X3oeK7X0RhjqsCfW4PigH041WMPjadQIOgSxeR5W4mKjOAGq/HkjU1fOGXAB98GHc6COxZb+Q1jwkBliaKJe8fTag4niEM0oFGdhKLScj5ctpORPZrRJDHO63Bql8L9MOdBWP4mNO4Gp9zoJAhLEsaEhcoSRSRQl/9NEIcEXaLYkJnHgaIyzu/ZzOtQape1M2DWfZC/F4beA2f+xhKEMWGmskSRoaqP1VgkVbTVnfq0TcMEjyOpRXLS4L1fQJNucNW70LyP1xEZYwKgskQRUr3BM1dl0Dgxls5NbY7sgFKF7fOcukzJreDajyAlFSJtJkFjwlVlA+7OqbEoqmjPgSK+XL+HS/u3JCrSnzGE5qTk7IA3LoMpF8K275xtbQZbkjAmzB3zikJVs2sykKp4ed5WVJUJp7T2OpTw5PPBopecIn4A5z8JrU/zNCRjTM0J+cp5uYWlvDF/Oxf2bkHbRtY/ERBvXwkbP4EO58BF/4BkS8jG1CYhnyiWbM8mv6ScqwbZh1e1Ki8FiXSK+PUaC93HQJ/xVp/JmFoo5Bv007ILAWjf2K4mqs2u5fDiWc6cEeAkir4TLEkYU0uF/BVF+v4CYqMiaFzX7t2vstJC+OYvMO9ZSGgESSleR2SMCQIhnyjSsgtJqV8HsW+7VZO2yCnit2+TUwJ8xONOxVdjTK0X0olCVdmcdZBWDeK9DiX0leY7/RJXf+jUaTLGGFdI91Es3JrNj3sOMrh9Q69DCU0/fg7f/9NZbj8Mbl9sScIY8zMhnShWpucCMC61lceRhJiCbPjgZnjzMlj+FpSVONujYryNyxgTlEK66WnD7jwaJ8ZSP8E+4PyiCmunO0X8CvfDGfc7D0sQxphKhHSi+HF3ntV2OhG5afD+jdC0B1z9ATTr5XVExpgQELJNTz6fsnH3QTo3TfQ6lOCmClu+cZaTW8N1M+HGLyxJGGP8FrKJIuNAEYWl5XRqYonimPZvg9cvhtdGHy7i13oQRIb0haQxpoaF7CdGZm4RAM2TbDa7n/GVw8JJ8MVjThmOC5+2In7GmJMWsokiK68YgMaJNiL7Z96aAD/OgU4jYNTfbYS1MaZKQjhROFcUTSxROCoW8etzhVOfqdflVp/JGFNlAe2jEJGRIrJBRDaJyANHef4eEVkrIitF5AsRaePvsbPyihGBhlbjCXYuhUnDDhfx63kZ9B5nScIYUy0ClihEJBJ4Djgf6A5MEJHuR+y2DEhV1d7Ae8Bf/T1+TmEpSXWiiYyoxR+GpYXw2UPw0jmQvxeSbOChMab6BbLpaSCwSVW3AIjI28AYYO2hHVT1qwr7/wBM9PfgB4vKqBsbsi1nVZe20Bldnb0Z+l8Dw/8AdZK9jsoYE4YC+UnbEkirsJ4ODKpk/xuAT472hIjcBNwE0Lq1M0FRXnEtTxSlhaA+uGa6U6fJGGMCJCjGUYjIRCAVePJoz6vqJFVNVdXUxo0bA5BfGxPFxk9h3jPOcvsz4fZFliSMMQEXyESxE6jYaJ7ibvsfInIu8CAwWlWL/T14uU9rT/9E/j54/5cw9XJY+e7hIn6R0d7GZYypFQL5lXwR0ElE2uEkiPHAlRV3EJF+wAvASFXdcyIHVyDs04QqrH4fPvl/UHQAznwATr/XivgZY2pUwBKFqpaJyO3AHCASmKyqa0TkMWCxqs7AaWqqC7zrzlC3Q1VH+3P8vKIyWiaH+ajs3DT48BZo2hPG/Msp5meMMTUsoI38qjoLmHXEtocqLJ97ssfOyiumb6ukKkQXpFRhy9fOBELJreG6WdCyP0REeh2ZMaaWCorO7JMRlp3Z2Vvg1YucQn6Hivi1OsWShDHGUyH7SetTRcJl5LGvHH74D3z5uNNBPeofVsTPGBM0QjJRFJWWU1zmo15cSIb/c1OvgE2fQeeRTqXXpJZeR2SMMT8JyU/a7Hzn9tCQrvNUVgIRUU4Rv75XQp/xTo2mcLlKMsaEjZDso9h30E0UoTpXdvoSmHQmLHrJWe95qVPt1ZKEMSYIhWSi2JvvjMsLuSuKkgKY8yC8fC4U5kCDdl5HZIwxxxWSTU9v/rAdgKb1QihRbJ8PH97sTE864HoY/ijEheHtvcaYsBNyiaKwpJzP1+3hV2e2J6V+vNfh+M/nTix07cfQ7nSvozHGGL+FXKJQ9+ep7Rp6GodfNnwCWRtg6N3Q7gy4bSFEhtwpN8bUciHZRxH08vfCezfAW+Nh9XsVivhZkjDGhB775KpOqrDqPaeIX3EenPUgDLnbivgZY0KaJYrqlJsG02+FZr2dIn5NunkdkTHGVJkliqry+WDLl9DxXKeI3/WzoUVfq89kjAkb1kdRFfs2O0X83rgMts1ztqUMsCRhjAkrIXdF4VPnvqc6MR5+GJeXwQ/PwVdPQGQsjP4XtLEifsaY8BR6icLnJApPS4xPHQebv4AuF8KFT0G95t7FYowxARZ6icK9okis6cqxZcUQEe0U8et/DfSbCD0usfpMxpiwF3J9FOU+52eNXlGkLYIXzoBFLzrrPS52CvlZkjDG1AIhlyjKfD4iBJLja2BsQkk+zP4tvDwcig9Cgw6Bf09jjAkyIdf0VFquNK8bS2REgL/Nb/8ePrgZcrbDKTfCOQ9DXL3AvqcxxgShkEsURaXldGhcN/Bv5CtzpiW9bha0HRL49zPGmCAVkomiR4sAfbNf9zHs3QCn3+sU8bt1gdVnMsbUeiHXR6HA4A7VXDn24B5451qYdhWsnW5F/IwxpoKQ/CSstkShCiunwewHnI7rs/8PhtzlNDkZY4wBQjRRRFTXbam5aTDjDmjRzxld3bhz9RzXGGPCSEgmiirx+ZxR1Z2GO0X8fjEHmvex+kzGGHMMIddHUSV7N8GUC+HNsbDtO2dby/6WJIwxphK144qivAzm/xO++hNEx8GYf0Mbu+XVGGP8UTsSxdTLYfOX0O0iuOApSGzqdUTGGBMyQi5RCBAd6UeLWWmRc/dSRCQMuM55dB8T4OiMMSb8hFwfRXRkxPHLd+z4AZ4fCgvdIn7dx1iSMMaYkxRyiaLSW2OLD8Ks/weTRzplwe12V2OMqbKQa3o6pm3fwQe3OGMjBt4E5zwEsTVQE8oYY8Jc+CQKgOg68IvZ0PpUryMxxpiwEdqJYu0M2LsRzrgP2g6FW+fbmAhjjKlmAe2jEJGRIrJBRDaJyANHeT5WRKa5zy8QkbZ+HThvN0y7Gt65GtZ/fLiInyUJY4ypdgG7ohCRSOA5YDiQDiwSkRmqurbCbjcA+1W1o4iMB/4CXFHZcevpAXjuFOf213MehtPusCJ+xhgTQIG8ohgIbFLVLapaArwNHHmP6hjgVXf5PeAckcor/jXx7YEm3eGWeXD6PZYkjDEmwALZR9ESSKuwng4MOtY+qlomIrlAQ2BvxZ1E5CbgJne1WG6Ysxrs1legEUecq1rMzsVhdi4Os3NxWJeTfWFIdGar6iRgEoCILFbVVI9DCgp2Lg6zc3GYnYvD7FwcJiKLT/a1gWx62gm0qrCe4m476j4iEgUkAfsCGJMxxpgTFMhEsQjoJCLtRCQGGA/MOGKfGcC17vJY4EtV1QDGZIwx5gQFrOnJ7XO4HZgDRAKTVXWNiDwGLFbVGcDLwOsisgnIxkkmxzMpUDGHIDsXh9m5OMzOxWF2Lg476XMh9gXeGGNMZUKuKKAxxpiaZYnCGGNMpYI2UQSs/EcI8uNc3CMia0VkpYh8ISJtvIizJhzvXFTY7zIRUREJ21sj/TkXIjLO/d1YIyJTazrGmuLH30hrEflKRJa5fycXeBFnoInIZBHZIyKrj/G8iMiz7nlaKSL9/TqwqgbdA6fzezPQHogBVgDdj9jnVuB5d3k8MM3ruD08F2cB8e7yLbX5XLj7JQJzgR+AVK/j9vD3ohOwDKjvrjfxOm4Pz8Uk4BZ3uTuwzeu4A3QuzgD6A6uP8fwFwCc4k4WeCizw57jBekURkPIfIeq450JVv1LVAnf1B5wxK+HIn98LgD/g1A0rqsngapg/5+KXwHOquh9AVffUcIw1xZ9zoUA9dzkJ2FWD8dUYVZ2LcwfpsYwBXlPHD0CyiDQ/3nGDNVEcrfxHy2Pto6plwKHyH+HGn3NR0Q043xjC0XHPhXsp3UpVZ9ZkYB7w5/eiM9BZROaJyA8iMrLGoqtZ/pyLR4CJIpIOzALuqJnQgs6Jfp4AIVLCw/hHRCYCqcCZXsfiBRGJAJ4GrvM4lGARhdP8NAznKnOuiPRS1Rwvg/LIBGCKqj4lIoNxxm/1VFWf14GFgmC9orDyH4f5cy4QkXOBB4HRqlpcQ7HVtOOdi0SgJ/C1iGzDaYOdEaYd2v78XqQDM1S1VFW3AhtxEke48edc3AC8A6Cq84E4nIKBtY1fnydHCtZEYeU/DjvuuRCRfsALOEkiXNuh4TjnQlVzVbWRqrZV1bY4/TWjVfWki6EFMX/+Rj7EuZpARBrhNEVtqcEYa4o/52IHcA6AiHTDSRRZNRplcJgBXOPe/XQqkKuqGcd7UVA2PWngyn+EHD/PxZNAXeBdtz9/h6qO9izoAPHzXNQKfp6LOcAIEVkLlAP3q2rYXXX7eS7uBV4UkV/jdGxfF45fLEXkLZwvB43c/piHgWgAVX0ep3/mAmATUABc79dxw/BcGWOMqUbB2vRkjDEmSFiiMMYYUylLFMYYYyplicIYY0ylLFEYY4yplCUKE5REpFxElld4tK1k34PV8H5TRGSr+15L3dG7J3qMl0Sku7v8uyOe+76qMbrHOXReVovIRyKSfJz9+4ZrpVRTc+z2WBOUROSgqtat7n0rOcYU4GNVfU9ERgB/U9XeVThelWM63nFF5FVgo6r+sZL9r8OpoHt7dcdiag+7ojAhQUTqunNtLBWRVSLys6qxItJcROZW+MZ9urt9hIjMd1/7rogc7wN8LtDRfe097rFWi8jd7rYEEZkpIivc7Ve4278WkVQR+TNQx43jTfe5g+7Pt0XkwgoxTxGRsSISKSJPisgid56AX/lxWubjFnQTkYHuv3GZiHwvIl3cUcqPAVe4sVzhxj5ZRBa6+x6t+q4x/8vr+un2sMfRHjgjiZe7jw9wqgjUc59rhDOy9NAV8UH3573Ag+5yJE7tp0Y4H/wJ7vbfAA8d5f2mAGPd5cuBBcAAYBWQgDPyfQ3QD7gMeLHCa5Pcn1/jzn9xKKYK+xyK8RLgVXc5BqeSZx3gJuD37vZYYDHQ7ihxHqzw73sXGOmu1wOi3OVzgffd5euAf1V4/RPARHc5Gaf+U4LX/9/2CO5HUJbwMAYoVNW+h1ZEJBp4QkTOAHw436SbApkVXrMImOzu+6GqLheRM3EmqpnnljeJwfkmfjRPisjvcWoA3YBTG+gDVc13Y/gvcDowG3hKRP6C01z17Qn8uz4BnhGRWGAkMFdVC93mrt4iMtbdLwmngN/WI15fR0SWu//+dcBnFfZ/VUQ64ZSoiD7G+48ARovIfe56HNDaPZYxR2WJwoSKq4DGwABVLRWnOmxcxR1Uda6bSC4EpojI08B+4DNVneDHe9yvqu8dWhGRc462k6puFGfeiwuAx0XkC1V9zJ9/hKoWicjXwHnAFTiT7IAz49gdqjrnOIcoVNW+IhKPU9voNuBZnMmavlLVS9yO/6+P8XoBLlPVDf7EawxYH4UJHUnAHjdJnAX8bF5wceYK362qLwIv4UwJ+QMwREQO9TkkiEhnP9/zW+BiEYkXkQScZqNvRaQFUKCqb+AUZDzavMOl7pXN0UzDKcZ26OoEnA/9Ww69RkQ6u+95VOrMaHgncK8cLrN/qFz0dRV2zcNpgjtkDnCHuJdX4lQeNqZSlihMqHgTSBWRVcA1wPqj7DMMWCEiy3C+rT+jqlk4H5xvichKnGanrv68oaouxem7WIjTZ/GSqi4DegEL3Sagh4HHj/LyScDKQ53ZR/gUZ3Kpz9WZuhOcxLYWWCoiq3HKxld6xe/GshJnUp6/An9y/+0VX/cV0P1QZzbOlUe0G9sad92YStntscYYYyplVxTGGGMqZYnCGGNMpSxRGGOMqZQlCmOMMZWyRGGMMaZSliiMMcZUyhKFMcaYSv1/irxJ8pEw4BkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create auc_roc score\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "\n",
    "# create plot\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# ROC curve for random model (looks like a straight line)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "# set axes\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# label graph\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "\n",
    "# display graph\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We receive a pretty steep curve here. It's a sign that our model is looking quite good. Based on the curvature, it seems like it might start to become more difficult to achieve significantly greater results than the model we have right now. However, we can still give it a shot, by seeing what happens if we tune our hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "\n",
    "Since there are many more 0 observations on our \"Exited\" column than there are 1s, the first thing to consider would be what results we would get balancing the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8425\n",
      "Recall: 0.4899497487437186\n",
      "Precision: 0.6351791530944625\n",
      "F1: 0.5531914893617021\n",
      "Confusion Matrix:\n",
      " [[1490  112]\n",
      " [ 203  195]]\n"
     ]
    }
   ],
   "source": [
    "# balanced classes\n",
    "\n",
    "balance_model = RandomForestClassifier(class_weight = 'balanced', random_state = 12345)\n",
    "balance_model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing our classes slightly improves our accuracy, but the tradeoff is that our recall has dropped too much and as a result, the F1 score is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples = 2 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "min samples = 3 : \n",
      "\n",
      "Accuracy: 0.85\n",
      "Recall: 0.5201005025125628\n",
      "Precision: 0.6550632911392406\n",
      "F1: 0.5798319327731092\n",
      "Confusion Matrix:\n",
      " [[1493  109]\n",
      " [ 191  207]]\n",
      "min samples = 4 : \n",
      "\n",
      "Accuracy: 0.851\n",
      "Recall: 0.5226130653266332\n",
      "Precision: 0.6582278481012658\n",
      "F1: 0.5826330532212886\n",
      "Confusion Matrix:\n",
      " [[1494  108]\n",
      " [ 190  208]]\n",
      "min samples = 5 : \n",
      "\n",
      "Accuracy: 0.8465\n",
      "Recall: 0.5025125628140703\n",
      "Precision: 0.6472491909385113\n",
      "F1: 0.5657708628005658\n",
      "Confusion Matrix:\n",
      " [[1493  109]\n",
      " [ 198  200]]\n",
      "min samples = 6 : \n",
      "\n",
      "Accuracy: 0.8485\n",
      "Recall: 0.5326633165829145\n",
      "Precision: 0.6443768996960486\n",
      "F1: 0.5832187070151307\n",
      "Confusion Matrix:\n",
      " [[1485  117]\n",
      " [ 186  212]]\n",
      "min samples = 7 : \n",
      "\n",
      "Accuracy: 0.85\n",
      "Recall: 0.542713567839196\n",
      "Precision: 0.6467065868263473\n",
      "F1: 0.5901639344262296\n",
      "Confusion Matrix:\n",
      " [[1484  118]\n",
      " [ 182  216]]\n",
      "min samples = 8 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5552763819095478\n",
      "Precision: 0.6480938416422287\n",
      "F1: 0.5981055480378891\n",
      "Confusion Matrix:\n",
      " [[1482  120]\n",
      " [ 177  221]]\n",
      "min samples = 9 : \n",
      "\n",
      "Accuracy: 0.8465\n",
      "Recall: 0.5552763819095478\n",
      "Precision: 0.6296296296296297\n",
      "F1: 0.5901201602136181\n",
      "Confusion Matrix:\n",
      " [[1472  130]\n",
      " [ 177  221]]\n",
      "min samples = 10 : \n",
      "\n",
      "Accuracy: 0.8465\n",
      "Recall: 0.5628140703517588\n",
      "Precision: 0.6274509803921569\n",
      "F1: 0.5933774834437086\n",
      "Confusion Matrix:\n",
      " [[1469  133]\n",
      " [ 174  224]]\n",
      "min samples = 11 : \n",
      "\n",
      "Accuracy: 0.8415\n",
      "Recall: 0.5728643216080402\n",
      "Precision: 0.608\n",
      "F1: 0.5899094437257438\n",
      "Confusion Matrix:\n",
      " [[1455  147]\n",
      " [ 170  228]]\n",
      "min samples = 12 : \n",
      "\n",
      "Accuracy: 0.8425\n",
      "Recall: 0.5829145728643216\n",
      "Precision: 0.6089238845144357\n",
      "F1: 0.5956354300385109\n",
      "Confusion Matrix:\n",
      " [[1453  149]\n",
      " [ 166  232]]\n",
      "min samples = 13 : \n",
      "\n",
      "Accuracy: 0.8375\n",
      "Recall: 0.585427135678392\n",
      "Precision: 0.5928753180661578\n",
      "F1: 0.5891276864728192\n",
      "Confusion Matrix:\n",
      " [[1442  160]\n",
      " [ 165  233]]\n",
      "min samples = 14 : \n",
      "\n",
      "Accuracy: 0.8355\n",
      "Recall: 0.5954773869346733\n",
      "Precision: 0.5851851851851851\n",
      "F1: 0.5902864259028642\n",
      "Confusion Matrix:\n",
      " [[1434  168]\n",
      " [ 161  237]]\n",
      "min samples = 15 : \n",
      "\n",
      "Accuracy: 0.834\n",
      "Recall: 0.5954773869346733\n",
      "Precision: 0.5808823529411765\n",
      "F1: 0.5880893300248139\n",
      "Confusion Matrix:\n",
      " [[1431  171]\n",
      " [ 161  237]]\n",
      "min samples = 16 : \n",
      "\n",
      "Accuracy: 0.8375\n",
      "Recall: 0.6256281407035176\n",
      "Precision: 0.5858823529411765\n",
      "F1: 0.6051032806804374\n",
      "Confusion Matrix:\n",
      " [[1426  176]\n",
      " [ 149  249]]\n",
      "min samples = 17 : \n",
      "\n",
      "Accuracy: 0.832\n",
      "Recall: 0.635678391959799\n",
      "Precision: 0.5698198198198198\n",
      "F1: 0.6009501187648456\n",
      "Confusion Matrix:\n",
      " [[1411  191]\n",
      " [ 145  253]]\n",
      "min samples = 18 : \n",
      "\n",
      "Accuracy: 0.831\n",
      "Recall: 0.635678391959799\n",
      "Precision: 0.5672645739910314\n",
      "F1: 0.5995260663507109\n",
      "Confusion Matrix:\n",
      " [[1409  193]\n",
      " [ 145  253]]\n",
      "min samples = 19 : \n",
      "\n",
      "Accuracy: 0.8305\n",
      "Recall: 0.6432160804020101\n",
      "Precision: 0.565121412803532\n",
      "F1: 0.6016451233842538\n",
      "Confusion Matrix:\n",
      " [[1405  197]\n",
      " [ 142  256]]\n",
      "min samples = 20 : \n",
      "\n",
      "Accuracy: 0.8265\n",
      "Recall: 0.6407035175879398\n",
      "Precision: 0.5555555555555556\n",
      "F1: 0.5950991831971996\n",
      "Confusion Matrix:\n",
      " [[1398  204]\n",
      " [ 143  255]]\n",
      "min samples = 21 : \n",
      "\n",
      "Accuracy: 0.829\n",
      "Recall: 0.6683417085427136\n",
      "Precision: 0.5588235294117647\n",
      "F1: 0.6086956521739132\n",
      "Confusion Matrix:\n",
      " [[1392  210]\n",
      " [ 132  266]]\n",
      "min samples = 22 : \n",
      "\n",
      "Accuracy: 0.8255\n",
      "Recall: 0.6608040201005025\n",
      "Precision: 0.5513626834381551\n",
      "F1: 0.6011428571428571\n",
      "Confusion Matrix:\n",
      " [[1388  214]\n",
      " [ 135  263]]\n",
      "min samples = 23 : \n",
      "\n",
      "Accuracy: 0.82\n",
      "Recall: 0.6532663316582915\n",
      "Precision: 0.5394190871369294\n",
      "F1: 0.5909090909090908\n",
      "Confusion Matrix:\n",
      " [[1380  222]\n",
      " [ 138  260]]\n",
      "min samples = 24 : \n",
      "\n",
      "Accuracy: 0.8205\n",
      "Recall: 0.6733668341708543\n",
      "Precision: 0.5392354124748491\n",
      "F1: 0.5988826815642458\n",
      "Confusion Matrix:\n",
      " [[1373  229]\n",
      " [ 130  268]]\n",
      "min samples = 25 : \n",
      "\n",
      "Accuracy: 0.8205\n",
      "Recall: 0.6809045226130653\n",
      "Precision: 0.5387673956262425\n",
      "F1: 0.6015538290788013\n",
      "Confusion Matrix:\n",
      " [[1370  232]\n",
      " [ 127  271]]\n",
      "min samples = 26 : \n",
      "\n",
      "Accuracy: 0.8195\n",
      "Recall: 0.7085427135678392\n",
      "Precision: 0.5351043643263758\n",
      "F1: 0.6097297297297298\n",
      "Confusion Matrix:\n",
      " [[1357  245]\n",
      " [ 116  282]]\n",
      "min samples = 27 : \n",
      "\n",
      "Accuracy: 0.8145\n",
      "Recall: 0.7135678391959799\n",
      "Precision: 0.5249537892791127\n",
      "F1: 0.6048988285410011\n",
      "Confusion Matrix:\n",
      " [[1345  257]\n",
      " [ 114  284]]\n",
      "min samples = 28 : \n",
      "\n",
      "Accuracy: 0.814\n",
      "Recall: 0.7010050251256281\n",
      "Precision: 0.5244360902255639\n",
      "F1: 0.6\n",
      "Confusion Matrix:\n",
      " [[1349  253]\n",
      " [ 119  279]]\n",
      "min samples = 29 : \n",
      "\n",
      "Accuracy: 0.8135\n",
      "Recall: 0.7060301507537688\n",
      "Precision: 0.5232774674115456\n",
      "F1: 0.6010695187165775\n",
      "Confusion Matrix:\n",
      " [[1346  256]\n",
      " [ 117  281]]\n",
      "min samples = 30 : \n",
      "\n",
      "Accuracy: 0.811\n",
      "Recall: 0.7236180904522613\n",
      "Precision: 0.5179856115107914\n",
      "F1: 0.6037735849056605\n",
      "Confusion Matrix:\n",
      " [[1334  268]\n",
      " [ 110  288]]\n",
      "min samples = 31 : \n",
      "\n",
      "Accuracy: 0.8115\n",
      "Recall: 0.7135678391959799\n",
      "Precision: 0.5191956124314442\n",
      "F1: 0.601058201058201\n",
      "Confusion Matrix:\n",
      " [[1339  263]\n",
      " [ 114  284]]\n",
      "min samples = 32 : \n",
      "\n",
      "Accuracy: 0.803\n",
      "Recall: 0.7160804020100503\n",
      "Precision: 0.5035335689045937\n",
      "F1: 0.5912863070539419\n",
      "Confusion Matrix:\n",
      " [[1321  281]\n",
      " [ 113  285]]\n",
      "min samples = 33 : \n",
      "\n",
      "Accuracy: 0.807\n",
      "Recall: 0.7361809045226131\n",
      "Precision: 0.5104529616724739\n",
      "F1: 0.6028806584362141\n",
      "Confusion Matrix:\n",
      " [[1321  281]\n",
      " [ 105  293]]\n",
      "min samples = 34 : \n",
      "\n",
      "Accuracy: 0.798\n",
      "Recall: 0.7261306532663316\n",
      "Precision: 0.4948630136986301\n",
      "F1: 0.5885947046843177\n",
      "Confusion Matrix:\n",
      " [[1307  295]\n",
      " [ 109  289]]\n",
      "min samples = 35 : \n",
      "\n",
      "Accuracy: 0.797\n",
      "Recall: 0.7386934673366834\n",
      "Precision: 0.49328859060402686\n",
      "F1: 0.5915492957746479\n",
      "Confusion Matrix:\n",
      " [[1300  302]\n",
      " [ 104  294]]\n",
      "min samples = 36 : \n",
      "\n",
      "Accuracy: 0.79\n",
      "Recall: 0.7261306532663316\n",
      "Precision: 0.4816666666666667\n",
      "F1: 0.5791583166332666\n",
      "Confusion Matrix:\n",
      " [[1291  311]\n",
      " [ 109  289]]\n",
      "min samples = 37 : \n",
      "\n",
      "Accuracy: 0.793\n",
      "Recall: 0.7562814070351759\n",
      "Precision: 0.48705501618122976\n",
      "F1: 0.5925196850393701\n",
      "Confusion Matrix:\n",
      " [[1285  317]\n",
      " [  97  301]]\n",
      "min samples = 38 : \n",
      "\n",
      "Accuracy: 0.787\n",
      "Recall: 0.7487437185929648\n",
      "Precision: 0.4775641025641026\n",
      "F1: 0.5831702544031311\n",
      "Confusion Matrix:\n",
      " [[1276  326]\n",
      " [ 100  298]]\n",
      "min samples = 39 : \n",
      "\n",
      "Accuracy: 0.7895\n",
      "Recall: 0.7688442211055276\n",
      "Precision: 0.4818897637795276\n",
      "F1: 0.5924491771539206\n",
      "Confusion Matrix:\n",
      " [[1273  329]\n",
      " [  92  306]]\n",
      "min samples = 40 : \n",
      "\n",
      "Accuracy: 0.7845\n",
      "Recall: 0.7562814070351759\n",
      "Precision: 0.47401574803149604\n",
      "F1: 0.5827686350435625\n",
      "Confusion Matrix:\n",
      " [[1268  334]\n",
      " [  97  301]]\n",
      "min samples = 41 : \n",
      "\n",
      "Accuracy: 0.7915\n",
      "Recall: 0.7613065326633166\n",
      "Precision: 0.4848\n",
      "F1: 0.5923753665689149\n",
      "Confusion Matrix:\n",
      " [[1280  322]\n",
      " [  95  303]]\n",
      "min samples = 42 : \n",
      "\n",
      "Accuracy: 0.7865\n",
      "Recall: 0.7713567839195979\n",
      "Precision: 0.4774494556765163\n",
      "F1: 0.5898174831892411\n",
      "Confusion Matrix:\n",
      " [[1266  336]\n",
      " [  91  307]]\n",
      "min samples = 43 : \n",
      "\n",
      "Accuracy: 0.7785\n",
      "Recall: 0.7763819095477387\n",
      "Precision: 0.4660633484162896\n",
      "F1: 0.5824693685202639\n",
      "Confusion Matrix:\n",
      " [[1248  354]\n",
      " [  89  309]]\n",
      "min samples = 44 : \n",
      "\n",
      "Accuracy: 0.7775\n",
      "Recall: 0.7839195979899497\n",
      "Precision: 0.46497764530551416\n",
      "F1: 0.5837231057062675\n",
      "Confusion Matrix:\n",
      " [[1243  359]\n",
      " [  86  312]]\n",
      "min samples = 45 : \n",
      "\n",
      "Accuracy: 0.778\n",
      "Recall: 0.7814070351758794\n",
      "Precision: 0.4655688622754491\n",
      "F1: 0.5834896810506566\n",
      "Confusion Matrix:\n",
      " [[1245  357]\n",
      " [  87  311]]\n",
      "min samples = 46 : \n",
      "\n",
      "Accuracy: 0.7765\n",
      "Recall: 0.7889447236180904\n",
      "Precision: 0.4638109305760709\n",
      "F1: 0.5841860465116279\n",
      "Confusion Matrix:\n",
      " [[1239  363]\n",
      " [  84  314]]\n",
      "min samples = 47 : \n",
      "\n",
      "Accuracy: 0.765\n",
      "Recall: 0.7914572864321608\n",
      "Precision: 0.44871794871794873\n",
      "F1: 0.5727272727272728\n",
      "Confusion Matrix:\n",
      " [[1215  387]\n",
      " [  83  315]]\n",
      "min samples = 48 : \n",
      "\n",
      "Accuracy: 0.775\n",
      "Recall: 0.7964824120603015\n",
      "Precision: 0.4620991253644315\n",
      "F1: 0.584870848708487\n",
      "Confusion Matrix:\n",
      " [[1233  369]\n",
      " [  81  317]]\n",
      "min samples = 49 : \n",
      "\n",
      "Accuracy: 0.767\n",
      "Recall: 0.8040201005025126\n",
      "Precision: 0.4519774011299435\n",
      "F1: 0.5786618444846293\n",
      "Confusion Matrix:\n",
      " [[1214  388]\n",
      " [  78  320]]\n",
      "min samples = 50 : \n",
      "\n",
      "Accuracy: 0.7665\n",
      "Recall: 0.7914572864321608\n",
      "Precision: 0.45064377682403434\n",
      "F1: 0.5742935278030993\n",
      "Confusion Matrix:\n",
      " [[1218  384]\n",
      " [  83  315]]\n",
      "min samples = 51 : \n",
      "\n",
      "Accuracy: 0.7645\n",
      "Recall: 0.7989949748743719\n",
      "Precision: 0.44851904090267986\n",
      "F1: 0.5745257452574526\n",
      "Confusion Matrix:\n",
      " [[1211  391]\n",
      " [  80  318]]\n",
      "min samples = 52 : \n",
      "\n",
      "Accuracy: 0.7595\n",
      "Recall: 0.7964824120603015\n",
      "Precision: 0.4421199442119944\n",
      "F1: 0.568609865470852\n",
      "Confusion Matrix:\n",
      " [[1202  400]\n",
      " [  81  317]]\n",
      "min samples = 53 : \n",
      "\n",
      "Accuracy: 0.7575\n",
      "Recall: 0.8065326633165829\n",
      "Precision: 0.4403292181069959\n",
      "F1: 0.5696539485359361\n",
      "Confusion Matrix:\n",
      " [[1194  408]\n",
      " [  77  321]]\n",
      "min samples = 54 : \n",
      "\n",
      "Accuracy: 0.753\n",
      "Recall: 0.8115577889447236\n",
      "Precision: 0.4353099730458221\n",
      "F1: 0.5666666666666667\n",
      "Confusion Matrix:\n",
      " [[1183  419]\n",
      " [  75  323]]\n",
      "min samples = 55 : \n",
      "\n",
      "Accuracy: 0.758\n",
      "Recall: 0.8115577889447236\n",
      "Precision: 0.4412568306010929\n",
      "F1: 0.5716814159292035\n",
      "Confusion Matrix:\n",
      " [[1193  409]\n",
      " [  75  323]]\n",
      "min samples = 56 : \n",
      "\n",
      "Accuracy: 0.748\n",
      "Recall: 0.8090452261306532\n",
      "Precision: 0.42933333333333334\n",
      "F1: 0.5609756097560975\n",
      "Confusion Matrix:\n",
      " [[1174  428]\n",
      " [  76  322]]\n",
      "min samples = 57 : \n",
      "\n",
      "Accuracy: 0.749\n",
      "Recall: 0.8015075376884422\n",
      "Precision: 0.4299191374663073\n",
      "F1: 0.5596491228070176\n",
      "Confusion Matrix:\n",
      " [[1179  423]\n",
      " [  79  319]]\n",
      "min samples = 58 : \n",
      "\n",
      "Accuracy: 0.7565\n",
      "Recall: 0.8140703517587939\n",
      "Precision: 0.4396200814111262\n",
      "F1: 0.5709251101321585\n",
      "Confusion Matrix:\n",
      " [[1189  413]\n",
      " [  74  324]]\n",
      "min samples = 59 : \n",
      "\n",
      "Accuracy: 0.754\n",
      "Recall: 0.8090452261306532\n",
      "Precision: 0.4363143631436314\n",
      "F1: 0.5669014084507042\n",
      "Confusion Matrix:\n",
      " [[1186  416]\n",
      " [  76  322]]\n",
      "min samples = 60 : \n",
      "\n",
      "Accuracy: 0.7465\n",
      "Recall: 0.8165829145728644\n",
      "Precision: 0.4281949934123847\n",
      "F1: 0.5617977528089888\n",
      "Confusion Matrix:\n",
      " [[1168  434]\n",
      " [  73  325]]\n",
      "min samples = 61 : \n",
      "\n",
      "Accuracy: 0.739\n",
      "Recall: 0.8190954773869347\n",
      "Precision: 0.42010309278350516\n",
      "F1: 0.5553662691652471\n",
      "Confusion Matrix:\n",
      " [[1152  450]\n",
      " [  72  326]]\n",
      "min samples = 62 : \n",
      "\n",
      "Accuracy: 0.741\n",
      "Recall: 0.8190954773869347\n",
      "Precision: 0.422279792746114\n",
      "F1: 0.5572649572649572\n",
      "Confusion Matrix:\n",
      " [[1156  446]\n",
      " [  72  326]]\n",
      "min samples = 63 : \n",
      "\n",
      "Accuracy: 0.739\n",
      "Recall: 0.8241206030150754\n",
      "Precision: 0.4205128205128205\n",
      "F1: 0.5568760611205432\n",
      "Confusion Matrix:\n",
      " [[1150  452]\n",
      " [  70  328]]\n",
      "min samples = 64 : \n",
      "\n",
      "Accuracy: 0.7455\n",
      "Recall: 0.8291457286432161\n",
      "Precision: 0.4280155642023346\n",
      "F1: 0.5645851154833191\n",
      "Confusion Matrix:\n",
      " [[1161  441]\n",
      " [  68  330]]\n",
      "min samples = 65 : \n",
      "\n",
      "Accuracy: 0.739\n",
      "Recall: 0.8291457286432161\n",
      "Precision: 0.42091836734693877\n",
      "F1: 0.5583756345177664\n",
      "Confusion Matrix:\n",
      " [[1148  454]\n",
      " [  68  330]]\n",
      "min samples = 66 : \n",
      "\n",
      "Accuracy: 0.739\n",
      "Recall: 0.8266331658291457\n",
      "Precision: 0.42071611253196933\n",
      "F1: 0.5576271186440678\n",
      "Confusion Matrix:\n",
      " [[1149  453]\n",
      " [  69  329]]\n",
      "min samples = 67 : \n",
      "\n",
      "Accuracy: 0.7395\n",
      "Recall: 0.8391959798994975\n",
      "Precision: 0.4222503160556258\n",
      "F1: 0.561816652649285\n",
      "Confusion Matrix:\n",
      " [[1145  457]\n",
      " [  64  334]]\n",
      "min samples = 68 : \n",
      "\n",
      "Accuracy: 0.74\n",
      "Recall: 0.8442211055276382\n",
      "Precision: 0.42317380352644834\n",
      "F1: 0.5637583892617449\n",
      "Confusion Matrix:\n",
      " [[1144  458]\n",
      " [  62  336]]\n",
      "min samples = 69 : \n",
      "\n",
      "Accuracy: 0.737\n",
      "Recall: 0.8417085427135679\n",
      "Precision: 0.4197994987468672\n",
      "F1: 0.560200668896321\n",
      "Confusion Matrix:\n",
      " [[1139  463]\n",
      " [  63  335]]\n",
      "min samples = 70 : \n",
      "\n",
      "Accuracy: 0.732\n",
      "Recall: 0.8391959798994975\n",
      "Precision: 0.4143920595533499\n",
      "F1: 0.5548172757475083\n",
      "Confusion Matrix:\n",
      " [[1130  472]\n",
      " [  64  334]]\n",
      "min samples = 71 : \n",
      "\n",
      "Accuracy: 0.734\n",
      "Recall: 0.8442211055276382\n",
      "Precision: 0.41687344913151364\n",
      "F1: 0.5581395348837209\n",
      "Confusion Matrix:\n",
      " [[1132  470]\n",
      " [  62  336]]\n",
      "min samples = 72 : \n",
      "\n",
      "Accuracy: 0.725\n",
      "Recall: 0.8391959798994975\n",
      "Precision: 0.4073170731707317\n",
      "F1: 0.548440065681445\n",
      "Confusion Matrix:\n",
      " [[1116  486]\n",
      " [  64  334]]\n",
      "min samples = 73 : \n",
      "\n",
      "Accuracy: 0.733\n",
      "Recall: 0.8467336683417085\n",
      "Precision: 0.4160493827160494\n",
      "F1: 0.5579470198675497\n",
      "Confusion Matrix:\n",
      " [[1129  473]\n",
      " [  61  337]]\n",
      "min samples = 74 : \n",
      "\n",
      "Accuracy: 0.7245\n",
      "Recall: 0.8542713567839196\n",
      "Precision: 0.40816326530612246\n",
      "F1: 0.5523964256701869\n",
      "Confusion Matrix:\n",
      " [[1109  493]\n",
      " [  58  340]]\n",
      "min samples = 75 : \n",
      "\n",
      "Accuracy: 0.7275\n",
      "Recall: 0.8567839195979899\n",
      "Precision: 0.41133896260554886\n",
      "F1: 0.5558272208638957\n",
      "Confusion Matrix:\n",
      " [[1114  488]\n",
      " [  57  341]]\n",
      "min samples = 76 : \n",
      "\n",
      "Accuracy: 0.7205\n",
      "Recall: 0.8417085427135679\n",
      "Precision: 0.40312876052948254\n",
      "F1: 0.5451586655817738\n",
      "Confusion Matrix:\n",
      " [[1106  496]\n",
      " [  63  335]]\n",
      "min samples = 77 : \n",
      "\n",
      "Accuracy: 0.7205\n",
      "Recall: 0.8542713567839196\n",
      "Precision: 0.4042806183115339\n",
      "F1: 0.5488297013720743\n",
      "Confusion Matrix:\n",
      " [[1101  501]\n",
      " [  58  340]]\n",
      "min samples = 78 : \n",
      "\n",
      "Accuracy: 0.7265\n",
      "Recall: 0.8542713567839196\n",
      "Precision: 0.4101326899879373\n",
      "F1: 0.5541972290138549\n",
      "Confusion Matrix:\n",
      " [[1113  489]\n",
      " [  58  340]]\n",
      "min samples = 79 : \n",
      "\n",
      "Accuracy: 0.723\n",
      "Recall: 0.8442211055276382\n",
      "Precision: 0.4057971014492754\n",
      "F1: 0.5481239804241436\n",
      "Confusion Matrix:\n",
      " [[1110  492]\n",
      " [  62  336]]\n",
      "min samples = 80 : \n",
      "\n",
      "Accuracy: 0.7195\n",
      "Recall: 0.8542713567839196\n",
      "Precision: 0.4033214709371293\n",
      "F1: 0.547945205479452\n",
      "Confusion Matrix:\n",
      " [[1099  503]\n",
      " [  58  340]]\n",
      "min samples = 81 : \n",
      "\n",
      "Accuracy: 0.7265\n",
      "Recall: 0.8492462311557789\n",
      "Precision: 0.40969696969696967\n",
      "F1: 0.552739165985282\n",
      "Confusion Matrix:\n",
      " [[1115  487]\n",
      " [  60  338]]\n",
      "min samples = 82 : \n",
      "\n",
      "Accuracy: 0.7235\n",
      "Recall: 0.8668341708542714\n",
      "Precision: 0.40828402366863903\n",
      "F1: 0.5551086082059533\n",
      "Confusion Matrix:\n",
      " [[1102  500]\n",
      " [  53  345]]\n",
      "min samples = 83 : \n",
      "\n",
      "Accuracy: 0.723\n",
      "Recall: 0.8618090452261307\n",
      "Precision: 0.40736342042755347\n",
      "F1: 0.5532258064516129\n",
      "Confusion Matrix:\n",
      " [[1103  499]\n",
      " [  55  343]]\n",
      "min samples = 84 : \n",
      "\n",
      "Accuracy: 0.7165\n",
      "Recall: 0.8618090452261307\n",
      "Precision: 0.40116959064327484\n",
      "F1: 0.547486033519553\n",
      "Confusion Matrix:\n",
      " [[1090  512]\n",
      " [  55  343]]\n",
      "min samples = 85 : \n",
      "\n",
      "Accuracy: 0.71\n",
      "Recall: 0.8542713567839196\n",
      "Precision: 0.39443155452436196\n",
      "F1: 0.5396825396825398\n",
      "Confusion Matrix:\n",
      " [[1080  522]\n",
      " [  58  340]]\n",
      "min samples = 86 : \n",
      "\n",
      "Accuracy: 0.711\n",
      "Recall: 0.8592964824120602\n",
      "Precision: 0.3958333333333333\n",
      "F1: 0.5419968304278922\n",
      "Confusion Matrix:\n",
      " [[1080  522]\n",
      " [  56  342]]\n",
      "min samples = 87 : \n",
      "\n",
      "Accuracy: 0.7075\n",
      "Recall: 0.864321608040201\n",
      "Precision: 0.3931428571428571\n",
      "F1: 0.5404556166535743\n",
      "Confusion Matrix:\n",
      " [[1071  531]\n",
      " [  54  344]]\n",
      "min samples = 88 : \n",
      "\n",
      "Accuracy: 0.7105\n",
      "Recall: 0.8592964824120602\n",
      "Precision: 0.3953757225433526\n",
      "F1: 0.5415676959619953\n",
      "Confusion Matrix:\n",
      " [[1079  523]\n",
      " [  56  342]]\n",
      "min samples = 89 : \n",
      "\n",
      "Accuracy: 0.7115\n",
      "Recall: 0.864321608040201\n",
      "Precision: 0.39677047289504036\n",
      "F1: 0.5438735177865612\n",
      "Confusion Matrix:\n",
      " [[1079  523]\n",
      " [  54  344]]\n",
      "min samples = 90 : \n",
      "\n",
      "Accuracy: 0.708\n",
      "Recall: 0.8618090452261307\n",
      "Precision: 0.393348623853211\n",
      "F1: 0.5401574803149606\n",
      "Confusion Matrix:\n",
      " [[1073  529]\n",
      " [  55  343]]\n",
      "min samples = 91 : \n",
      "\n",
      "Accuracy: 0.7105\n",
      "Recall: 0.871859296482412\n",
      "Precision: 0.3965714285714286\n",
      "F1: 0.5451688923802043\n",
      "Confusion Matrix:\n",
      " [[1074  528]\n",
      " [  51  347]]\n",
      "min samples = 92 : \n",
      "\n",
      "Accuracy: 0.7115\n",
      "Recall: 0.8768844221105527\n",
      "Precision: 0.3979475484606613\n",
      "F1: 0.5474509803921568\n",
      "Confusion Matrix:\n",
      " [[1074  528]\n",
      " [  49  349]]\n",
      "min samples = 93 : \n",
      "\n",
      "Accuracy: 0.7095\n",
      "Recall: 0.8743718592964824\n",
      "Precision: 0.39590443686006827\n",
      "F1: 0.5450274079874706\n",
      "Confusion Matrix:\n",
      " [[1071  531]\n",
      " [  50  348]]\n",
      "min samples = 94 : \n",
      "\n",
      "Accuracy: 0.708\n",
      "Recall: 0.8768844221105527\n",
      "Precision: 0.3947963800904977\n",
      "F1: 0.5444617784711389\n",
      "Confusion Matrix:\n",
      " [[1067  535]\n",
      " [  49  349]]\n",
      "min samples = 95 : \n",
      "\n",
      "Accuracy: 0.705\n",
      "Recall: 0.8693467336683417\n",
      "Precision: 0.3914027149321267\n",
      "F1: 0.5397815912636504\n",
      "Confusion Matrix:\n",
      " [[1064  538]\n",
      " [  52  346]]\n",
      "min samples = 96 : \n",
      "\n",
      "Accuracy: 0.704\n",
      "Recall: 0.8793969849246231\n",
      "Precision: 0.39149888143176736\n",
      "F1: 0.541795665634675\n",
      "Confusion Matrix:\n",
      " [[1058  544]\n",
      " [  48  350]]\n",
      "min samples = 97 : \n",
      "\n",
      "Accuracy: 0.702\n",
      "Recall: 0.8743718592964824\n",
      "Precision: 0.38926174496644295\n",
      "F1: 0.5386996904024768\n",
      "Confusion Matrix:\n",
      " [[1056  546]\n",
      " [  50  348]]\n",
      "min samples = 98 : \n",
      "\n",
      "Accuracy: 0.709\n",
      "Recall: 0.8768844221105527\n",
      "Precision: 0.3956916099773243\n",
      "F1: 0.5453125000000001\n",
      "Confusion Matrix:\n",
      " [[1069  533]\n",
      " [  49  349]]\n",
      "min samples = 99 : \n",
      "\n",
      "Accuracy: 0.704\n",
      "Recall: 0.8793969849246231\n",
      "Precision: 0.39149888143176736\n",
      "F1: 0.541795665634675\n",
      "Confusion Matrix:\n",
      " [[1058  544]\n",
      " [  48  350]]\n"
     ]
    }
   ],
   "source": [
    "# create lists to store our values\n",
    "\n",
    "ms_f1 = []\n",
    "\n",
    "# create a loop\n",
    "\n",
    "for depth in range(2,100):\n",
    "    # create model\n",
    "    \n",
    "    sample_model = RandomForestClassifier(random_state=12345, min_samples_split=depth)\n",
    "    sample_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # predict value\n",
    "    \n",
    "    predicted_valid = sample_model.predict(features_valid)\n",
    "    \n",
    "    # store prediction's f1 score\n",
    "    \n",
    "    training_score =  f1_score(target_valid, predicted_valid)\n",
    "    ms_f1.append(training_score)\n",
    "\n",
    "    # print results\n",
    "    \n",
    "    print(\"min samples =\", depth, \": \\n\")\n",
    "\n",
    "    model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of F1 maximum: 25 \n",
      "Training set maximum: 0.6097297297297298\n"
     ]
    }
   ],
   "source": [
    "# find maximum accuracy\n",
    "\n",
    "print(\"Depth of F1 maximum:\", ms_f1.index(max(ms_f1))+1,\n",
    "      \"\\nTraining set maximum:\", max(ms_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ms_f1)\n",
    "\n",
    "# plot details\n",
    "\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('min samples')\n",
    "plt.title(\"Random Forest Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While tuning the number of minimum samples does seem to have an effect on our model's overall F1 score, it is definitely not doing so in a major way. If anything, we see a steady decrease in the overall F1 score as we make our samples require more minimum values. While our F1 score is \"maximized\" at higher than the default (at 10 minimum samples to split), it is not in any sort of pattern and thus we will ignore this hyperparameter and continue with using a default.\n",
    "\n",
    "We will also try tuning our model's maximum depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth = 1 : \n",
      "\n",
      "Accuracy: 0.199\n",
      "Recall: 1.0\n",
      "Precision: 0.199\n",
      "F1: 0.33194328607172646\n",
      "Confusion Matrix:\n",
      " [[   0 1602]\n",
      " [   0  398]]\n",
      "max depth = 2 : \n",
      "\n",
      "Accuracy: 0.201\n",
      "Recall: 1.0\n",
      "Precision: 0.19939879759519039\n",
      "F1: 0.3324979114452799\n",
      "Confusion Matrix:\n",
      " [[   4 1598]\n",
      " [   0  398]]\n",
      "max depth = 3 : \n",
      "\n",
      "Accuracy: 0.3705\n",
      "Recall: 0.9874371859296482\n",
      "Precision: 0.23861566484517305\n",
      "F1: 0.38435207823960876\n",
      "Confusion Matrix:\n",
      " [[ 348 1254]\n",
      " [   5  393]]\n",
      "max depth = 4 : \n",
      "\n",
      "Accuracy: 0.4045\n",
      "Recall: 0.9824120603015075\n",
      "Precision: 0.24825396825396825\n",
      "F1: 0.39635073492143946\n",
      "Confusion Matrix:\n",
      " [[ 418 1184]\n",
      " [   7  391]]\n",
      "max depth = 5 : \n",
      "\n",
      "Accuracy: 0.473\n",
      "Recall: 0.9723618090452262\n",
      "Precision: 0.27062937062937065\n",
      "F1: 0.4234135667396061\n",
      "Confusion Matrix:\n",
      " [[ 559 1043]\n",
      " [  11  387]]\n",
      "max depth = 6 : \n",
      "\n",
      "Accuracy: 0.551\n",
      "Recall: 0.964824120603015\n",
      "Precision: 0.3028391167192429\n",
      "F1: 0.46098439375750294\n",
      "Confusion Matrix:\n",
      " [[718 884]\n",
      " [ 14 384]]\n",
      "max depth = 7 : \n",
      "\n",
      "Accuracy: 0.5935\n",
      "Recall: 0.957286432160804\n",
      "Precision: 0.32370433305012747\n",
      "F1: 0.48380952380952386\n",
      "Confusion Matrix:\n",
      " [[806 796]\n",
      " [ 17 381]]\n",
      "max depth = 8 : \n",
      "\n",
      "Accuracy: 0.6545\n",
      "Recall: 0.907035175879397\n",
      "Precision: 0.3556650246305419\n",
      "F1: 0.5109695682944091\n",
      "Confusion Matrix:\n",
      " [[948 654]\n",
      " [ 37 361]]\n",
      "max depth = 9 : \n",
      "\n",
      "Accuracy: 0.6945\n",
      "Recall: 0.8768844221105527\n",
      "Precision: 0.38309549945115257\n",
      "F1: 0.5332314744079449\n",
      "Confusion Matrix:\n",
      " [[1040  562]\n",
      " [  49  349]]\n",
      "max depth = 10 : \n",
      "\n",
      "Accuracy: 0.7295\n",
      "Recall: 0.8442211055276382\n",
      "Precision: 0.41226993865030676\n",
      "F1: 0.5539983511953833\n",
      "Confusion Matrix:\n",
      " [[1123  479]\n",
      " [  62  336]]\n",
      "max depth = 11 : \n",
      "\n",
      "Accuracy: 0.7615\n",
      "Recall: 0.7814070351758794\n",
      "Precision: 0.44365192582025675\n",
      "F1: 0.5659690627843493\n",
      "Confusion Matrix:\n",
      " [[1212  390]\n",
      " [  87  311]]\n",
      "max depth = 12 : \n",
      "\n",
      "Accuracy: 0.795\n",
      "Recall: 0.7412060301507538\n",
      "Precision: 0.4900332225913621\n",
      "F1: 0.59\n",
      "Confusion Matrix:\n",
      " [[1295  307]\n",
      " [ 103  295]]\n",
      "max depth = 13 : \n",
      "\n",
      "Accuracy: 0.8075\n",
      "Recall: 0.7035175879396985\n",
      "Precision: 0.5118829981718465\n",
      "F1: 0.5925925925925927\n",
      "Confusion Matrix:\n",
      " [[1335  267]\n",
      " [ 118  280]]\n",
      "max depth = 14 : \n",
      "\n",
      "Accuracy: 0.828\n",
      "Recall: 0.635678391959799\n",
      "Precision: 0.5597345132743363\n",
      "F1: 0.5952941176470589\n",
      "Confusion Matrix:\n",
      " [[1403  199]\n",
      " [ 145  253]]\n",
      "max depth = 15 : \n",
      "\n",
      "Accuracy: 0.828\n",
      "Recall: 0.585427135678392\n",
      "Precision: 0.5655339805825242\n",
      "F1: 0.5753086419753087\n",
      "Confusion Matrix:\n",
      " [[1423  179]\n",
      " [ 165  233]]\n",
      "max depth = 16 : \n",
      "\n",
      "Accuracy: 0.835\n",
      "Recall: 0.5603015075376885\n",
      "Precision: 0.58994708994709\n",
      "F1: 0.5747422680412372\n",
      "Confusion Matrix:\n",
      " [[1447  155]\n",
      " [ 175  223]]\n",
      "max depth = 17 : \n",
      "\n",
      "Accuracy: 0.8445\n",
      "Recall: 0.5603015075376885\n",
      "Precision: 0.6211699164345403\n",
      "F1: 0.5891677675033025\n",
      "Confusion Matrix:\n",
      " [[1466  136]\n",
      " [ 175  223]]\n",
      "max depth = 18 : \n",
      "\n",
      "Accuracy: 0.843\n",
      "Recall: 0.5376884422110553\n",
      "Precision: 0.622093023255814\n",
      "F1: 0.5768194070080863\n",
      "Confusion Matrix:\n",
      " [[1472  130]\n",
      " [ 184  214]]\n",
      "max depth = 19 : \n",
      "\n",
      "Accuracy: 0.8465\n",
      "Recall: 0.5376884422110553\n",
      "Precision: 0.6350148367952523\n",
      "F1: 0.582312925170068\n",
      "Confusion Matrix:\n",
      " [[1479  123]\n",
      " [ 184  214]]\n",
      "max depth = 20 : \n",
      "\n",
      "Accuracy: 0.8455\n",
      "Recall: 0.5100502512562815\n",
      "Precision: 0.6403785488958991\n",
      "F1: 0.5678321678321678\n",
      "Confusion Matrix:\n",
      " [[1488  114]\n",
      " [ 195  203]]\n",
      "max depth = 21 : \n",
      "\n",
      "Accuracy: 0.846\n",
      "Recall: 0.5125628140703518\n",
      "Precision: 0.6415094339622641\n",
      "F1: 0.5698324022346367\n",
      "Confusion Matrix:\n",
      " [[1488  114]\n",
      " [ 194  204]]\n",
      "max depth = 22 : \n",
      "\n",
      "Accuracy: 0.851\n",
      "Recall: 0.5276381909547738\n",
      "Precision: 0.65625\n",
      "F1: 0.5849582172701949\n",
      "Confusion Matrix:\n",
      " [[1492  110]\n",
      " [ 188  210]]\n",
      "max depth = 23 : \n",
      "\n",
      "Accuracy: 0.848\n",
      "Recall: 0.5201005025125628\n",
      "Precision: 0.646875\n",
      "F1: 0.5766016713091922\n",
      "Confusion Matrix:\n",
      " [[1489  113]\n",
      " [ 191  207]]\n",
      "max depth = 24 : \n",
      "\n",
      "Accuracy: 0.8485\n",
      "Recall: 0.5100502512562815\n",
      "Precision: 0.6527331189710611\n",
      "F1: 0.5726375176304654\n",
      "Confusion Matrix:\n",
      " [[1494  108]\n",
      " [ 195  203]]\n",
      "max depth = 25 : \n",
      "\n",
      "Accuracy: 0.851\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6612903225806451\n",
      "F1: 0.5790960451977399\n",
      "Confusion Matrix:\n",
      " [[1497  105]\n",
      " [ 193  205]]\n",
      "max depth = 26 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5100502512562815\n",
      "Precision: 0.6655737704918033\n",
      "F1: 0.5775248933143671\n",
      "Confusion Matrix:\n",
      " [[1500  102]\n",
      " [ 195  203]]\n",
      "max depth = 27 : \n",
      "\n",
      "Accuracy: 0.8525\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6677524429967426\n",
      "F1: 0.5815602836879432\n",
      "Confusion Matrix:\n",
      " [[1500  102]\n",
      " [ 193  205]]\n",
      "max depth = 28 : \n",
      "\n",
      "Accuracy: 0.85\n",
      "Recall: 0.5125628140703518\n",
      "Precision: 0.6580645161290323\n",
      "F1: 0.576271186440678\n",
      "Confusion Matrix:\n",
      " [[1496  106]\n",
      " [ 194  204]]\n",
      "max depth = 29 : \n",
      "\n",
      "Accuracy: 0.85\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.657051282051282\n",
      "F1: 0.5774647887323943\n",
      "Confusion Matrix:\n",
      " [[1495  107]\n",
      " [ 193  205]]\n",
      "max depth = 30 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 31 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 32 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 33 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 34 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 35 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 36 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 37 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 38 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 39 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 40 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 41 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 42 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 43 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 44 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 45 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 46 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 47 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 48 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 49 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "max depth = 50 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n"
     ]
    }
   ],
   "source": [
    "# create lists to store our values\n",
    "\n",
    "md_f1 = []\n",
    "\n",
    "# create a loop\n",
    "\n",
    "for depth in range(1,51):\n",
    "    # create model\n",
    "    \n",
    "    depth_model = RandomForestClassifier(random_state=12345, max_depth=depth)\n",
    "    depth_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # predict value\n",
    "    \n",
    "    predicted_valid = depth_model.predict(features_valid)\n",
    "    \n",
    "    # store prediction's f1 score\n",
    "    \n",
    "    training_score =  f1_score(target_valid, predicted_valid)\n",
    "    md_f1.append(training_score)\n",
    "\n",
    "    # print results\n",
    "    \n",
    "    print(\"max depth =\", depth, \": \\n\")\n",
    "\n",
    "    model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of F1 maximum: 14 \n",
      "Training set maximum: 0.5952941176470589\n"
     ]
    }
   ],
   "source": [
    "# find maximum accuracy\n",
    "\n",
    "print(\"Depth of F1 maximum:\", md_f1.index(max(md_f1))+1,\n",
    "      \"\\nTraining set maximum:\", max(md_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(md_f1)\n",
    "\n",
    "# plot details\n",
    "\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('max depth')\n",
    "plt.title(\"Random Forest Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This maximum depth modification model is not providing improvement, even as it approaches its peak. We will not pursue it, here. We will try a minimum samples leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples leaf = 1 : \n",
      "\n",
      "Accuracy: 0.8515\n",
      "Recall: 0.5150753768844221\n",
      "Precision: 0.6634304207119741\n",
      "F1: 0.5799151343705798\n",
      "Confusion Matrix:\n",
      " [[1498  104]\n",
      " [ 193  205]]\n",
      "min samples leaf = 2 : \n",
      "\n",
      "Accuracy: 0.837\n",
      "Recall: 0.6030150753768844\n",
      "Precision: 0.5882352941176471\n",
      "F1: 0.5955334987593052\n",
      "Confusion Matrix:\n",
      " [[1434  168]\n",
      " [ 158  240]]\n",
      "min samples leaf = 3 : \n",
      "\n",
      "Accuracy: 0.828\n",
      "Recall: 0.6608040201005025\n",
      "Precision: 0.5572033898305084\n",
      "F1: 0.6045977011494252\n",
      "Confusion Matrix:\n",
      " [[1393  209]\n",
      " [ 135  263]]\n",
      "min samples leaf = 4 : \n",
      "\n",
      "Accuracy: 0.816\n",
      "Recall: 0.6984924623115578\n",
      "Precision: 0.5285171102661597\n",
      "F1: 0.6017316017316017\n",
      "Confusion Matrix:\n",
      " [[1354  248]\n",
      " [ 120  278]]\n",
      "min samples leaf = 5 : \n",
      "\n",
      "Accuracy: 0.8145\n",
      "Recall: 0.7638190954773869\n",
      "Precision: 0.5232358003442341\n",
      "F1: 0.6210418794688458\n",
      "Confusion Matrix:\n",
      " [[1325  277]\n",
      " [  94  304]]\n",
      "min samples leaf = 6 : \n",
      "\n",
      "Accuracy: 0.794\n",
      "Recall: 0.7587939698492462\n",
      "Precision: 0.4886731391585761\n",
      "F1: 0.594488188976378\n",
      "Confusion Matrix:\n",
      " [[1286  316]\n",
      " [  96  302]]\n",
      "min samples leaf = 7 : \n",
      "\n",
      "Accuracy: 0.7855\n",
      "Recall: 0.7889447236180904\n",
      "Precision: 0.4764795144157815\n",
      "F1: 0.5941343424787133\n",
      "Confusion Matrix:\n",
      " [[1257  345]\n",
      " [  84  314]]\n",
      "min samples leaf = 8 : \n",
      "\n",
      "Accuracy: 0.7715\n",
      "Recall: 0.8040201005025126\n",
      "Precision: 0.45779685264663805\n",
      "F1: 0.5834092980856882\n",
      "Confusion Matrix:\n",
      " [[1223  379]\n",
      " [  78  320]]\n",
      "min samples leaf = 9 : \n",
      "\n",
      "Accuracy: 0.758\n",
      "Recall: 0.8266331658291457\n",
      "Precision: 0.4422043010752688\n",
      "F1: 0.5761821366024519\n",
      "Confusion Matrix:\n",
      " [[1187  415]\n",
      " [  69  329]]\n",
      "min samples leaf = 10 : \n",
      "\n",
      "Accuracy: 0.746\n",
      "Recall: 0.8316582914572864\n",
      "Precision: 0.42875647668393785\n",
      "F1: 0.5658119658119658\n",
      "Confusion Matrix:\n",
      " [[1161  441]\n",
      " [  67  331]]\n",
      "min samples leaf = 11 : \n",
      "\n",
      "Accuracy: 0.744\n",
      "Recall: 0.8366834170854272\n",
      "Precision: 0.4269230769230769\n",
      "F1: 0.565365025466893\n",
      "Confusion Matrix:\n",
      " [[1155  447]\n",
      " [  65  333]]\n",
      "min samples leaf = 12 : \n",
      "\n",
      "Accuracy: 0.7295\n",
      "Recall: 0.8517587939698492\n",
      "Precision: 0.41291108404384896\n",
      "F1: 0.5561936013125512\n",
      "Confusion Matrix:\n",
      " [[1120  482]\n",
      " [  59  339]]\n",
      "min samples leaf = 13 : \n",
      "\n",
      "Accuracy: 0.7285\n",
      "Recall: 0.8542713567839196\n",
      "Precision: 0.4121212121212121\n",
      "F1: 0.5560098119378577\n",
      "Confusion Matrix:\n",
      " [[1117  485]\n",
      " [  58  340]]\n",
      "min samples leaf = 14 : \n",
      "\n",
      "Accuracy: 0.7265\n",
      "Recall: 0.8592964824120602\n",
      "Precision: 0.4105642256902761\n",
      "F1: 0.5556458164094232\n",
      "Confusion Matrix:\n",
      " [[1111  491]\n",
      " [  56  342]]\n",
      "min samples leaf = 15 : \n",
      "\n",
      "Accuracy: 0.717\n",
      "Recall: 0.864321608040201\n",
      "Precision: 0.40186915887850466\n",
      "F1: 0.5486443381180224\n",
      "Confusion Matrix:\n",
      " [[1090  512]\n",
      " [  54  344]]\n",
      "min samples leaf = 16 : \n",
      "\n",
      "Accuracy: 0.7115\n",
      "Recall: 0.871859296482412\n",
      "Precision: 0.3974799541809851\n",
      "F1: 0.5460267505900864\n",
      "Confusion Matrix:\n",
      " [[1076  526]\n",
      " [  51  347]]\n",
      "min samples leaf = 17 : \n",
      "\n",
      "Accuracy: 0.7045\n",
      "Recall: 0.8793969849246231\n",
      "Precision: 0.3919372900335946\n",
      "F1: 0.5422153369481023\n",
      "Confusion Matrix:\n",
      " [[1059  543]\n",
      " [  48  350]]\n",
      "min samples leaf = 18 : \n",
      "\n",
      "Accuracy: 0.6965\n",
      "Recall: 0.8743718592964824\n",
      "Precision: 0.38453038674033146\n",
      "F1: 0.5341519570222563\n",
      "Confusion Matrix:\n",
      " [[1045  557]\n",
      " [  50  348]]\n",
      "min samples leaf = 19 : \n",
      "\n",
      "Accuracy: 0.693\n",
      "Recall: 0.8869346733668342\n",
      "Precision: 0.38286334056399135\n",
      "F1: 0.5348484848484848\n",
      "Confusion Matrix:\n",
      " [[1033  569]\n",
      " [  45  353]]\n",
      "min samples leaf = 20 : \n",
      "\n",
      "Accuracy: 0.6865\n",
      "Recall: 0.8969849246231156\n",
      "Precision: 0.37857900318133614\n",
      "F1: 0.5324384787472036\n",
      "Confusion Matrix:\n",
      " [[1016  586]\n",
      " [  41  357]]\n",
      "min samples leaf = 21 : \n",
      "\n",
      "Accuracy: 0.6845\n",
      "Recall: 0.8869346733668342\n",
      "Precision: 0.3759318423855165\n",
      "F1: 0.5280478683620046\n",
      "Confusion Matrix:\n",
      " [[1016  586]\n",
      " [  45  353]]\n",
      "min samples leaf = 22 : \n",
      "\n",
      "Accuracy: 0.678\n",
      "Recall: 0.8894472361809045\n",
      "Precision: 0.3710691823899371\n",
      "F1: 0.5236686390532544\n",
      "Confusion Matrix:\n",
      " [[1002  600]\n",
      " [  44  354]]\n",
      "min samples leaf = 23 : \n",
      "\n",
      "Accuracy: 0.676\n",
      "Recall: 0.8894472361809045\n",
      "Precision: 0.3695198329853862\n",
      "F1: 0.5221238938053098\n",
      "Confusion Matrix:\n",
      " [[998 604]\n",
      " [ 44 354]]\n",
      "min samples leaf = 24 : \n",
      "\n",
      "Accuracy: 0.6725\n",
      "Recall: 0.9020100502512562\n",
      "Precision: 0.3682051282051282\n",
      "F1: 0.5229424617625638\n",
      "Confusion Matrix:\n",
      " [[986 616]\n",
      " [ 39 359]]\n",
      "min samples leaf = 25 : \n",
      "\n",
      "Accuracy: 0.661\n",
      "Recall: 0.9020100502512562\n",
      "Precision: 0.35971943887775554\n",
      "F1: 0.5143266475644699\n",
      "Confusion Matrix:\n",
      " [[963 639]\n",
      " [ 39 359]]\n",
      "min samples leaf = 26 : \n",
      "\n",
      "Accuracy: 0.6665\n",
      "Recall: 0.9095477386934674\n",
      "Precision: 0.364551863041289\n",
      "F1: 0.5204888569374551\n",
      "Confusion Matrix:\n",
      " [[971 631]\n",
      " [ 36 362]]\n",
      "min samples leaf = 27 : \n",
      "\n",
      "Accuracy: 0.66\n",
      "Recall: 0.9045226130653267\n",
      "Precision: 0.3592814371257485\n",
      "F1: 0.5142857142857143\n",
      "Confusion Matrix:\n",
      " [[960 642]\n",
      " [ 38 360]]\n",
      "min samples leaf = 28 : \n",
      "\n",
      "Accuracy: 0.657\n",
      "Recall: 0.8919597989949749\n",
      "Precision: 0.3557114228456914\n",
      "F1: 0.5085959885386819\n",
      "Confusion Matrix:\n",
      " [[959 643]\n",
      " [ 43 355]]\n",
      "min samples leaf = 29 : \n",
      "\n",
      "Accuracy: 0.657\n",
      "Recall: 0.907035175879397\n",
      "Precision: 0.3574257425742574\n",
      "F1: 0.5127840909090908\n",
      "Confusion Matrix:\n",
      " [[953 649]\n",
      " [ 37 361]]\n",
      "min samples leaf = 30 : \n",
      "\n",
      "Accuracy: 0.6545\n",
      "Recall: 0.9120603015075377\n",
      "Precision: 0.3562315996074583\n",
      "F1: 0.5123500352858151\n",
      "Confusion Matrix:\n",
      " [[946 656]\n",
      " [ 35 363]]\n",
      "min samples leaf = 31 : \n",
      "\n",
      "Accuracy: 0.6525\n",
      "Recall: 0.9120603015075377\n",
      "Precision: 0.3548387096774194\n",
      "F1: 0.5109078114004223\n",
      "Confusion Matrix:\n",
      " [[942 660]\n",
      " [ 35 363]]\n",
      "min samples leaf = 32 : \n",
      "\n",
      "Accuracy: 0.6505\n",
      "Recall: 0.9170854271356784\n",
      "Precision: 0.35402521823472355\n",
      "F1: 0.5108467459762072\n",
      "Confusion Matrix:\n",
      " [[936 666]\n",
      " [ 33 365]]\n",
      "min samples leaf = 33 : \n",
      "\n",
      "Accuracy: 0.651\n",
      "Recall: 0.9195979899497487\n",
      "Precision: 0.3546511627906977\n",
      "F1: 0.5118881118881119\n",
      "Confusion Matrix:\n",
      " [[936 666]\n",
      " [ 32 366]]\n",
      "min samples leaf = 34 : \n",
      "\n",
      "Accuracy: 0.6425\n",
      "Recall: 0.9170854271356784\n",
      "Precision: 0.34861509073543456\n",
      "F1: 0.5051903114186852\n",
      "Confusion Matrix:\n",
      " [[920 682]\n",
      " [ 33 365]]\n",
      "min samples leaf = 35 : \n",
      "\n",
      "Accuracy: 0.6375\n",
      "Recall: 0.9195979899497487\n",
      "Precision: 0.34560906515580736\n",
      "F1: 0.5024021962937543\n",
      "Confusion Matrix:\n",
      " [[909 693]\n",
      " [ 32 366]]\n",
      "min samples leaf = 36 : \n",
      "\n",
      "Accuracy: 0.632\n",
      "Recall: 0.9221105527638191\n",
      "Precision: 0.3423507462686567\n",
      "F1: 0.4993197278911564\n",
      "Confusion Matrix:\n",
      " [[897 705]\n",
      " [ 31 367]]\n",
      "min samples leaf = 37 : \n",
      "\n",
      "Accuracy: 0.637\n",
      "Recall: 0.914572864321608\n",
      "Precision: 0.3446969696969697\n",
      "F1: 0.500687757909216\n",
      "Confusion Matrix:\n",
      " [[910 692]\n",
      " [ 34 364]]\n",
      "min samples leaf = 38 : \n",
      "\n",
      "Accuracy: 0.6365\n",
      "Recall: 0.9195979899497487\n",
      "Precision: 0.3449575871819039\n",
      "F1: 0.5017135023989033\n",
      "Confusion Matrix:\n",
      " [[907 695]\n",
      " [ 32 366]]\n",
      "min samples leaf = 39 : \n",
      "\n",
      "Accuracy: 0.629\n",
      "Recall: 0.9195979899497487\n",
      "Precision: 0.34014869888475835\n",
      "F1: 0.49660786974219806\n",
      "Confusion Matrix:\n",
      " [[892 710]\n",
      " [ 32 366]]\n",
      "min samples leaf = 40 : \n",
      "\n",
      "Accuracy: 0.632\n",
      "Recall: 0.9221105527638191\n",
      "Precision: 0.3423507462686567\n",
      "F1: 0.4993197278911564\n",
      "Confusion Matrix:\n",
      " [[897 705]\n",
      " [ 31 367]]\n",
      "min samples leaf = 41 : \n",
      "\n",
      "Accuracy: 0.6285\n",
      "Recall: 0.9221105527638191\n",
      "Precision: 0.340129749768304\n",
      "F1: 0.4969532836831415\n",
      "Confusion Matrix:\n",
      " [[890 712]\n",
      " [ 31 367]]\n",
      "min samples leaf = 42 : \n",
      "\n",
      "Accuracy: 0.622\n",
      "Recall: 0.9170854271356784\n",
      "Precision: 0.33547794117647056\n",
      "F1: 0.49125168236877514\n",
      "Confusion Matrix:\n",
      " [[879 723]\n",
      " [ 33 365]]\n",
      "min samples leaf = 43 : \n",
      "\n",
      "Accuracy: 0.6175\n",
      "Recall: 0.9246231155778895\n",
      "Precision: 0.33363553943789664\n",
      "F1: 0.49033977348434377\n",
      "Confusion Matrix:\n",
      " [[867 735]\n",
      " [ 30 368]]\n",
      "min samples leaf = 44 : \n",
      "\n",
      "Accuracy: 0.619\n",
      "Recall: 0.9296482412060302\n",
      "Precision: 0.3351449275362319\n",
      "F1: 0.492676431424767\n",
      "Confusion Matrix:\n",
      " [[868 734]\n",
      " [ 28 370]]\n",
      "min samples leaf = 45 : \n",
      "\n",
      "Accuracy: 0.6205\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.3369467028003613\n",
      "F1: 0.49568106312292354\n",
      "Confusion Matrix:\n",
      " [[868 734]\n",
      " [ 25 373]]\n",
      "min samples leaf = 46 : \n",
      "\n",
      "Accuracy: 0.6155\n",
      "Recall: 0.9246231155778895\n",
      "Precision: 0.3324299909665763\n",
      "F1: 0.48903654485049836\n",
      "Confusion Matrix:\n",
      " [[863 739]\n",
      " [ 30 368]]\n",
      "min samples leaf = 47 : \n",
      "\n",
      "Accuracy: 0.6105\n",
      "Recall: 0.9296482412060302\n",
      "Precision: 0.33006244424620873\n",
      "F1: 0.4871626069782752\n",
      "Confusion Matrix:\n",
      " [[851 751]\n",
      " [ 28 370]]\n",
      "min samples leaf = 48 : \n",
      "\n",
      "Accuracy: 0.6125\n",
      "Recall: 0.9271356783919598\n",
      "Precision: 0.3309417040358744\n",
      "F1: 0.4877726371447455\n",
      "Confusion Matrix:\n",
      " [[856 746]\n",
      " [ 29 369]]\n",
      "min samples leaf = 49 : \n",
      "\n",
      "Accuracy: 0.615\n",
      "Recall: 0.9346733668341709\n",
      "Precision: 0.3333333333333333\n",
      "F1: 0.49141347424042275\n",
      "Confusion Matrix:\n",
      " [[858 744]\n",
      " [ 26 372]]\n",
      "min samples leaf = 50 : \n",
      "\n",
      "Accuracy: 0.612\n",
      "Recall: 0.9271356783919598\n",
      "Precision: 0.33064516129032256\n",
      "F1: 0.48745046235138706\n",
      "Confusion Matrix:\n",
      " [[855 747]\n",
      " [ 29 369]]\n",
      "min samples leaf = 51 : \n",
      "\n",
      "Accuracy: 0.611\n",
      "Recall: 0.9396984924623115\n",
      "Precision: 0.33156028368794327\n",
      "F1: 0.490170380078637\n",
      "Confusion Matrix:\n",
      " [[848 754]\n",
      " [ 24 374]]\n",
      "min samples leaf = 52 : \n",
      "\n",
      "Accuracy: 0.6065\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.32863436123348017\n",
      "F1: 0.4866275277234181\n",
      "Confusion Matrix:\n",
      " [[840 762]\n",
      " [ 25 373]]\n",
      "min samples leaf = 53 : \n",
      "\n",
      "Accuracy: 0.613\n",
      "Recall: 0.9346733668341709\n",
      "Precision: 0.33214285714285713\n",
      "F1: 0.4901185770750988\n",
      "Confusion Matrix:\n",
      " [[854 748]\n",
      " [ 26 372]]\n",
      "min samples leaf = 54 : \n",
      "\n",
      "Accuracy: 0.609\n",
      "Recall: 0.9346733668341709\n",
      "Precision: 0.32978723404255317\n",
      "F1: 0.4875491480996068\n",
      "Confusion Matrix:\n",
      " [[846 756]\n",
      " [ 26 372]]\n",
      "min samples leaf = 55 : \n",
      "\n",
      "Accuracy: 0.61\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.33067375886524825\n",
      "F1: 0.4888597640891219\n",
      "Confusion Matrix:\n",
      " [[847 755]\n",
      " [ 25 373]]\n",
      "min samples leaf = 56 : \n",
      "\n",
      "Accuracy: 0.611\n",
      "Recall: 0.9321608040201005\n",
      "Precision: 0.3306595365418895\n",
      "F1: 0.4881578947368421\n",
      "Confusion Matrix:\n",
      " [[851 751]\n",
      " [ 27 371]]\n",
      "min samples leaf = 57 : \n",
      "\n",
      "Accuracy: 0.6055\n",
      "Recall: 0.9296482412060302\n",
      "Precision: 0.3271441202475685\n",
      "F1: 0.48397645519947674\n",
      "Confusion Matrix:\n",
      " [[841 761]\n",
      " [ 28 370]]\n",
      "min samples leaf = 58 : \n",
      "\n",
      "Accuracy: 0.6025\n",
      "Recall: 0.9296482412060302\n",
      "Precision: 0.3254177660510114\n",
      "F1: 0.48208469055374586\n",
      "Confusion Matrix:\n",
      " [[835 767]\n",
      " [ 28 370]]\n",
      "min samples leaf = 59 : \n",
      "\n",
      "Accuracy: 0.5985\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.32406602953953084\n",
      "F1: 0.4816010329244674\n",
      "Confusion Matrix:\n",
      " [[824 778]\n",
      " [ 25 373]]\n",
      "min samples leaf = 60 : \n",
      "\n",
      "Accuracy: 0.6025\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.326334208223972\n",
      "F1: 0.4841012329656068\n",
      "Confusion Matrix:\n",
      " [[832 770]\n",
      " [ 25 373]]\n",
      "min samples leaf = 61 : \n",
      "\n",
      "Accuracy: 0.5985\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.32406602953953084\n",
      "F1: 0.4816010329244674\n",
      "Confusion Matrix:\n",
      " [[824 778]\n",
      " [ 25 373]]\n",
      "min samples leaf = 62 : \n",
      "\n",
      "Accuracy: 0.595\n",
      "Recall: 0.9296482412060302\n",
      "Precision: 0.3211805555555556\n",
      "F1: 0.4774193548387097\n",
      "Confusion Matrix:\n",
      " [[820 782]\n",
      " [ 28 370]]\n",
      "min samples leaf = 63 : \n",
      "\n",
      "Accuracy: 0.5955\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.3233018056749785\n",
      "F1: 0.4817424727738629\n",
      "Confusion Matrix:\n",
      " [[815 787]\n",
      " [ 22 376]]\n",
      "min samples leaf = 64 : \n",
      "\n",
      "Accuracy: 0.589\n",
      "Recall: 0.9422110552763819\n",
      "Precision: 0.3194207836456559\n",
      "F1: 0.47709923664122145\n",
      "Confusion Matrix:\n",
      " [[803 799]\n",
      " [ 23 375]]\n",
      "min samples leaf = 65 : \n",
      "\n",
      "Accuracy: 0.593\n",
      "Recall: 0.949748743718593\n",
      "Precision: 0.3225255972696246\n",
      "F1: 0.4815286624203822\n",
      "Confusion Matrix:\n",
      " [[808 794]\n",
      " [ 20 378]]\n",
      "min samples leaf = 66 : \n",
      "\n",
      "Accuracy: 0.593\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.3219178082191781\n",
      "F1: 0.48020434227330777\n",
      "Confusion Matrix:\n",
      " [[810 792]\n",
      " [ 22 376]]\n",
      "min samples leaf = 67 : \n",
      "\n",
      "Accuracy: 0.5915\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.3210930828351836\n",
      "F1: 0.4792861695347355\n",
      "Confusion Matrix:\n",
      " [[807 795]\n",
      " [ 22 376]]\n",
      "min samples leaf = 68 : \n",
      "\n",
      "Accuracy: 0.59\n",
      "Recall: 0.9396984924623115\n",
      "Precision: 0.31965811965811963\n",
      "F1: 0.47704081632653056\n",
      "Confusion Matrix:\n",
      " [[806 796]\n",
      " [ 24 374]]\n",
      "min samples leaf = 69 : \n",
      "\n",
      "Accuracy: 0.586\n",
      "Recall: 0.9396984924623115\n",
      "Precision: 0.3174872665534805\n",
      "F1: 0.47461928934010156\n",
      "Confusion Matrix:\n",
      " [[798 804]\n",
      " [ 24 374]]\n",
      "min samples leaf = 70 : \n",
      "\n",
      "Accuracy: 0.58\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.31397306397306396\n",
      "F1: 0.4703656998738966\n",
      "Confusion Matrix:\n",
      " [[787 815]\n",
      " [ 25 373]]\n",
      "min samples leaf = 71 : \n",
      "\n",
      "Accuracy: 0.591\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.32081911262798635\n",
      "F1: 0.4789808917197452\n",
      "Confusion Matrix:\n",
      " [[806 796]\n",
      " [ 22 376]]\n",
      "min samples leaf = 72 : \n",
      "\n",
      "Accuracy: 0.6\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.32582322357019067\n",
      "F1: 0.48453608247422686\n",
      "Confusion Matrix:\n",
      " [[824 778]\n",
      " [ 22 376]]\n",
      "min samples leaf = 73 : \n",
      "\n",
      "Accuracy: 0.595\n",
      "Recall: 0.9472361809045227\n",
      "Precision: 0.32332761578044594\n",
      "F1: 0.48209718670076723\n",
      "Confusion Matrix:\n",
      " [[813 789]\n",
      " [ 21 377]]\n",
      "min samples leaf = 74 : \n",
      "\n",
      "Accuracy: 0.5895\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.32\n",
      "F1: 0.47806738715829633\n",
      "Confusion Matrix:\n",
      " [[803 799]\n",
      " [ 22 376]]\n",
      "min samples leaf = 75 : \n",
      "\n",
      "Accuracy: 0.585\n",
      "Recall: 0.9472361809045227\n",
      "Precision: 0.3178752107925801\n",
      "F1: 0.47601010101010094\n",
      "Confusion Matrix:\n",
      " [[793 809]\n",
      " [ 21 377]]\n",
      "min samples leaf = 76 : \n",
      "\n",
      "Accuracy: 0.583\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.3155668358714044\n",
      "F1: 0.47215189873417723\n",
      "Confusion Matrix:\n",
      " [[793 809]\n",
      " [ 25 373]]\n",
      "min samples leaf = 77 : \n",
      "\n",
      "Accuracy: 0.581\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.31543624161073824\n",
      "F1: 0.4729559748427673\n",
      "Confusion Matrix:\n",
      " [[786 816]\n",
      " [ 22 376]]\n",
      "min samples leaf = 78 : \n",
      "\n",
      "Accuracy: 0.5805\n",
      "Recall: 0.9396984924623115\n",
      "Precision: 0.31455004205214465\n",
      "F1: 0.4713295526149968\n",
      "Confusion Matrix:\n",
      " [[787 815]\n",
      " [ 24 374]]\n",
      "min samples leaf = 79 : \n",
      "\n",
      "Accuracy: 0.578\n",
      "Recall: 0.9522613065326633\n",
      "Precision: 0.31478405315614616\n",
      "F1: 0.4731585518102372\n",
      "Confusion Matrix:\n",
      " [[777 825]\n",
      " [ 19 379]]\n",
      "min samples leaf = 80 : \n",
      "\n",
      "Accuracy: 0.566\n",
      "Recall: 0.9547738693467337\n",
      "Precision: 0.3089430894308943\n",
      "F1: 0.46683046683046686\n",
      "Confusion Matrix:\n",
      " [[752 850]\n",
      " [ 18 380]]\n",
      "min samples leaf = 81 : \n",
      "\n",
      "Accuracy: 0.5735\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.3105745212323064\n",
      "F1: 0.46654158849280797\n",
      "Confusion Matrix:\n",
      " [[774 828]\n",
      " [ 25 373]]\n",
      "min samples leaf = 82 : \n",
      "\n",
      "Accuracy: 0.5695\n",
      "Recall: 0.9371859296482412\n",
      "Precision: 0.30851943755169564\n",
      "F1: 0.4642190416925949\n",
      "Confusion Matrix:\n",
      " [[766 836]\n",
      " [ 25 373]]\n",
      "min samples leaf = 83 : \n",
      "\n",
      "Accuracy: 0.561\n",
      "Recall: 0.9447236180904522\n",
      "Precision: 0.3051948051948052\n",
      "F1: 0.4613496932515338\n",
      "Confusion Matrix:\n",
      " [[746 856]\n",
      " [ 22 376]]\n",
      "min samples leaf = 84 : \n",
      "\n",
      "Accuracy: 0.5755\n",
      "Recall: 0.9547738693467337\n",
      "Precision: 0.3137902559867878\n",
      "F1: 0.47234307022995653\n",
      "Confusion Matrix:\n",
      " [[771 831]\n",
      " [ 18 380]]\n",
      "min samples leaf = 85 : \n",
      "\n",
      "Accuracy: 0.57\n",
      "Recall: 0.9522613065326633\n",
      "Precision: 0.31065573770491806\n",
      "F1: 0.46847960444993814\n",
      "Confusion Matrix:\n",
      " [[761 841]\n",
      " [ 19 379]]\n",
      "min samples leaf = 86 : \n",
      "\n",
      "Accuracy: 0.5645\n",
      "Recall: 0.957286432160804\n",
      "Precision: 0.308502024291498\n",
      "F1: 0.4666258420085732\n",
      "Confusion Matrix:\n",
      " [[748 854]\n",
      " [ 17 381]]\n",
      "min samples leaf = 87 : \n",
      "\n",
      "Accuracy: 0.5645\n",
      "Recall: 0.957286432160804\n",
      "Precision: 0.308502024291498\n",
      "F1: 0.4666258420085732\n",
      "Confusion Matrix:\n",
      " [[748 854]\n",
      " [ 17 381]]\n",
      "min samples leaf = 88 : \n",
      "\n",
      "Accuracy: 0.5655\n",
      "Recall: 0.9597989949748744\n",
      "Precision: 0.30931174089068825\n",
      "F1: 0.46785058175137784\n",
      "Confusion Matrix:\n",
      " [[749 853]\n",
      " [ 16 382]]\n",
      "min samples leaf = 89 : \n",
      "\n",
      "Accuracy: 0.5675\n",
      "Recall: 0.9623115577889447\n",
      "Precision: 0.31062449310624496\n",
      "F1: 0.4696505211526671\n",
      "Confusion Matrix:\n",
      " [[752 850]\n",
      " [ 15 383]]\n",
      "min samples leaf = 90 : \n",
      "\n",
      "Accuracy: 0.5685\n",
      "Recall: 0.9547738693467337\n",
      "Precision: 0.31020408163265306\n",
      "F1: 0.46826863832409116\n",
      "Confusion Matrix:\n",
      " [[757 845]\n",
      " [ 18 380]]\n",
      "min samples leaf = 91 : \n",
      "\n",
      "Accuracy: 0.5715\n",
      "Recall: 0.9547738693467337\n",
      "Precision: 0.3117309269893355\n",
      "F1: 0.4700061842918986\n",
      "Confusion Matrix:\n",
      " [[763 839]\n",
      " [ 18 380]]\n",
      "min samples leaf = 92 : \n",
      "\n",
      "Accuracy: 0.558\n",
      "Recall: 0.949748743718593\n",
      "Precision: 0.30434782608695654\n",
      "F1: 0.4609756097560976\n",
      "Confusion Matrix:\n",
      " [[738 864]\n",
      " [ 20 378]]\n",
      "min samples leaf = 93 : \n",
      "\n",
      "Accuracy: 0.5615\n",
      "Recall: 0.9522613065326633\n",
      "Precision: 0.30638641875505257\n",
      "F1: 0.46360856269113143\n",
      "Confusion Matrix:\n",
      " [[744 858]\n",
      " [ 19 379]]\n",
      "min samples leaf = 94 : \n",
      "\n",
      "Accuracy: 0.5665\n",
      "Recall: 0.9547738693467337\n",
      "Precision: 0.30919446704637915\n",
      "F1: 0.4671173939766441\n",
      "Confusion Matrix:\n",
      " [[753 849]\n",
      " [ 18 380]]\n",
      "min samples leaf = 95 : \n",
      "\n",
      "Accuracy: 0.5605\n",
      "Recall: 0.9623115577889447\n",
      "Precision: 0.3071371291098637\n",
      "F1: 0.46565349544072954\n",
      "Confusion Matrix:\n",
      " [[738 864]\n",
      " [ 15 383]]\n",
      "min samples leaf = 96 : \n",
      "\n",
      "Accuracy: 0.5585\n",
      "Recall: 0.9597989949748744\n",
      "Precision: 0.3058446757405925\n",
      "F1: 0.46387370977534914\n",
      "Confusion Matrix:\n",
      " [[735 867]\n",
      " [ 16 382]]\n",
      "min samples leaf = 97 : \n",
      "\n",
      "Accuracy: 0.5565\n",
      "Recall: 0.9597989949748744\n",
      "Precision: 0.3048683160415004\n",
      "F1: 0.46274984857662016\n",
      "Confusion Matrix:\n",
      " [[731 871]\n",
      " [ 16 382]]\n",
      "min samples leaf = 98 : \n",
      "\n",
      "Accuracy: 0.5525\n",
      "Recall: 0.9623115577889447\n",
      "Precision: 0.30324623911322246\n",
      "F1: 0.46116797110174595\n",
      "Confusion Matrix:\n",
      " [[722 880]\n",
      " [ 15 383]]\n",
      "min samples leaf = 99 : \n",
      "\n",
      "Accuracy: 0.5505\n",
      "Recall: 0.9597989949748744\n",
      "Precision: 0.3019762845849802\n",
      "F1: 0.4594107035478051\n",
      "Confusion Matrix:\n",
      " [[719 883]\n",
      " [ 16 382]]\n",
      "min samples leaf = 100 : \n",
      "\n",
      "Accuracy: 0.55\n",
      "Recall: 0.9623115577889447\n",
      "Precision: 0.3020504731861199\n",
      "F1: 0.45978391356542625\n",
      "Confusion Matrix:\n",
      " [[717 885]\n",
      " [ 15 383]]\n"
     ]
    }
   ],
   "source": [
    "# create lists to store our values\n",
    "\n",
    "leaf_f1 = []\n",
    "\n",
    "# create a loop\n",
    "\n",
    "for depth in range(1,101):\n",
    "    # create model\n",
    "    \n",
    "    leaf_model = RandomForestClassifier(random_state=12345, min_samples_leaf=depth)\n",
    "    leaf_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # predict value\n",
    "    \n",
    "    predicted_valid = leaf_model.predict(features_valid)\n",
    "    \n",
    "    # store prediction's f1 score\n",
    "    \n",
    "    training_score =  f1_score(target_valid, predicted_valid)\n",
    "    leaf_f1.append(training_score)\n",
    "\n",
    "    # print results\n",
    "    \n",
    "    print(\"min samples leaf =\", depth, \": \\n\")\n",
    "\n",
    "    model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min samples leaf maximum: 5 \n",
      "Training set maximum: 0.6210418794688458\n"
     ]
    }
   ],
   "source": [
    "# find maximum accuracy\n",
    "\n",
    "print(\"Min samples leaf maximum:\", leaf_f1.index(max(leaf_f1))+1,\n",
    "      \"\\nTraining set maximum:\", max(leaf_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(leaf_f1)\n",
    "\n",
    "# plot details\n",
    "\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('min samples leaf')\n",
    "plt.title(\"Random Forest Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8145\n",
      "Recall: 0.7638190954773869\n",
      "Precision: 0.5232358003442341\n",
      "F1: 0.6210418794688458\n",
      "Confusion Matrix:\n",
      " [[1325  277]\n",
      " [  94  304]]\n"
     ]
    }
   ],
   "source": [
    "# leaf model\n",
    "\n",
    "model = RandomForestClassifier(random_state=12345, min_samples_leaf=5)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "# predict value\n",
    "    \n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "model_metrics(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like adjusting our minimum samples leaf value has some sort of effect that makes a curve that does not appear to be random. It quickly drops but when we split by leaves of minimum size 5, we will end up getting a model that is overall better. The precision dropped, but the recall grew at a faster rate. There are some ways that this model could be considered inferior, since it results in more false positives.\n",
    "\n",
    "In this instance, we should choose between the min samples model and the threshold model based on our goal. The aim of our predictive model is to identify which customers are likely to leave so that we can aim to retain their services. There will be relatively fewer consequences if the model returns a false positive - so long as it is not returning too many positives. However, each time we return a false negative, that is an extra customer lost. When our goal is to keep as many customers as possible, we should probably err on the side of our higher F1 model even if it is more likely to give us a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "\n",
    "Finally, we should test the model that we decided was our best fit with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.813\n",
      "Recall: 0.738498789346247\n",
      "Precision: 0.5341506129597198\n",
      "F1: 0.6199186991869919\n",
      "Confusion Matrix:\n",
      " [[1321  266]\n",
      " [ 108  305]]\n"
     ]
    }
   ],
   "source": [
    "# leaf model\n",
    "\n",
    "model = RandomForestClassifier(random_state=12345, min_samples_leaf=5)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predicted_test = model.predict(features_test)\n",
    "\n",
    "model_metrics(target_test, predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little troublesome. Using our leaf model our F1 score has dipped below the threshold we were looking for, and the reason is specifically because it is too likely to return a false positive. Tweaking the leaf model might get us past that threshold, but with the issue being the imbalance of the model, it might end up being too unreliable.\n",
    "\n",
    "Instead, let's at least give a look at the thresholded model - the one that also had our validation set return an F1 above 0.59 but that had its recall and precision be more similar to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8475\n",
      "Recall: 0.6440677966101694\n",
      "Precision: 0.6273584905660378\n",
      "F1: 0.6356033452807647\n",
      "Confusion Matrix:\n",
      " [[1429  158]\n",
      " [ 147  266]]\n"
     ]
    }
   ],
   "source": [
    "# threshold model\n",
    "\n",
    "model = RandomForestClassifier(random_state = 12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "# set predictions with the threshold\n",
    "\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "predicted_test = probabilities_one_test > 0.4\n",
    "\n",
    "model_metrics(target_test, predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the highest F1 score yet, which seems to say that the threshold model is working better. Our recall and precision are relatively close. It would seem to suggest that this model will work more reliably with newer data, and we also have a much more stable idea of what proportion of our model will be erroneous. With that in mind, this should probably be our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In order to achieve our desired F1 score of over 0.59, we first tested a few of our models to see which style would prove the most promising and chose to use a random forest classifier. We checked our models for accuracy, recall, precision, and their F1 scores as we tuned them, modifying by testing for upsampling, downsampling, and altering the classification threshold. We found a model that has a high ROC curve and the suitable F1 score.\n",
    "\n",
    "We tuned our hyperparameters to find the highest F1 score we could, but identified that it might not be better than one of our earlier models since it was not strictly more accurate but rather was more likely to catch the true positives. When we used our test set, this proved to be true, as the one that did not modify hyperparameters was ultimately a better fitted model."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 686,
    "start_time": "2022-03-13T18:01:49.437Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-13T18:02:03.418Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-13T18:02:09.796Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-13T18:02:15.270Z"
   },
   {
    "duration": 344,
    "start_time": "2022-03-13T18:02:58.326Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-13T18:03:02.094Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-13T18:03:36.700Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-13T18:03:43.553Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-13T22:44:26.464Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-13T22:44:48.818Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-13T22:45:01.061Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-13T22:46:13.726Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-13T22:49:27.980Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-13T22:49:32.646Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-13T22:49:42.383Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-13T22:49:44.723Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-13T22:57:05.164Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-13T22:57:09.230Z"
   },
   {
    "duration": 484,
    "start_time": "2022-03-13T22:57:51.333Z"
   },
   {
    "duration": 405,
    "start_time": "2022-03-13T22:58:03.598Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-13T22:58:36.014Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-13T23:54:18.665Z"
   },
   {
    "duration": 338,
    "start_time": "2022-03-13T23:55:08.137Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-13T23:55:18.961Z"
   },
   {
    "duration": 303,
    "start_time": "2022-03-13T23:55:23.970Z"
   },
   {
    "duration": 189,
    "start_time": "2022-03-13T23:56:36.717Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-13T23:56:40.315Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-14T00:02:27.232Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-14T00:04:41.127Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-14T00:04:49.677Z"
   },
   {
    "duration": 293,
    "start_time": "2022-03-14T00:04:56.950Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-14T00:05:02.297Z"
   },
   {
    "duration": 291,
    "start_time": "2022-03-14T00:05:29.798Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-14T00:05:32.670Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-14T00:06:11.482Z"
   },
   {
    "duration": 309,
    "start_time": "2022-03-14T00:07:00.505Z"
   },
   {
    "duration": 8132,
    "start_time": "2022-03-14T00:07:11.123Z"
   },
   {
    "duration": 4031,
    "start_time": "2022-03-14T00:07:27.167Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-14T00:07:37.001Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-14T00:07:45.799Z"
   },
   {
    "duration": 300,
    "start_time": "2022-03-14T00:10:25.523Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-14T00:10:45.089Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-14T00:10:52.111Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-14T00:12:11.229Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-14T00:12:24.135Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-14T00:15:55.719Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-14T00:15:58.833Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-14T00:17:35.330Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-14T00:17:46.089Z"
   },
   {
    "duration": 308,
    "start_time": "2022-03-14T00:18:16.454Z"
   },
   {
    "duration": 26,
    "start_time": "2022-03-14T00:42:59.946Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-14T00:43:03.970Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-14T00:43:11.364Z"
   },
   {
    "duration": 2,
    "start_time": "2022-03-14T00:43:58.926Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-14T00:44:17.367Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-14T01:54:16.227Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-14T01:54:41.230Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-14T01:55:15.143Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-14T01:55:23.402Z"
   },
   {
    "duration": 45,
    "start_time": "2022-03-14T01:55:50.630Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-14T01:55:51.293Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-14T04:14:19.791Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-14T04:15:51.931Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-14T04:16:29.455Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-14T04:16:59.403Z"
   },
   {
    "duration": 335,
    "start_time": "2022-03-14T04:17:14.574Z"
   },
   {
    "duration": 72,
    "start_time": "2022-03-14T04:17:27.248Z"
   },
   {
    "duration": 370,
    "start_time": "2022-03-14T04:17:31.280Z"
   },
   {
    "duration": 45,
    "start_time": "2022-03-14T04:17:39.115Z"
   },
   {
    "duration": 151,
    "start_time": "2022-03-14T04:17:41.570Z"
   },
   {
    "duration": 344,
    "start_time": "2022-03-14T04:17:48.020Z"
   },
   {
    "duration": 322,
    "start_time": "2022-03-14T04:17:59.727Z"
   },
   {
    "duration": 219,
    "start_time": "2022-03-15T02:30:43.103Z"
   },
   {
    "duration": 1100,
    "start_time": "2022-03-15T02:30:50.269Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-15T02:30:51.371Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-15T02:30:51.397Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-15T02:30:51.414Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-15T02:30:51.438Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-15T02:30:51.443Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-15T02:30:51.453Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-15T02:30:51.460Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-15T02:30:51.478Z"
   },
   {
    "duration": 53,
    "start_time": "2022-03-15T02:30:51.486Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-15T02:30:51.540Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-15T02:30:51.566Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-15T02:30:51.613Z"
   },
   {
    "duration": 361,
    "start_time": "2022-03-15T02:30:51.646Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-15T02:30:52.009Z"
   },
   {
    "duration": 266,
    "start_time": "2022-03-15T02:31:19.802Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-15T02:31:29.004Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-15T02:31:31.677Z"
   },
   {
    "duration": 367,
    "start_time": "2022-03-15T02:33:21.125Z"
   },
   {
    "duration": 55,
    "start_time": "2022-03-15T02:34:29.386Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-15T02:34:32.888Z"
   },
   {
    "duration": 242,
    "start_time": "2022-03-15T04:20:47.767Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-15T04:21:00.195Z"
   },
   {
    "duration": 232,
    "start_time": "2022-03-15T04:21:04.845Z"
   },
   {
    "duration": 235,
    "start_time": "2022-03-15T04:30:17.130Z"
   },
   {
    "duration": 274,
    "start_time": "2022-03-15T04:30:29.895Z"
   },
   {
    "duration": 292,
    "start_time": "2022-03-15T04:31:37.976Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-15T04:31:51.637Z"
   },
   {
    "duration": 71,
    "start_time": "2022-03-15T04:31:54.496Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-15T04:32:13.199Z"
   },
   {
    "duration": 112,
    "start_time": "2022-03-15T04:32:41.827Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-15T04:32:43.860Z"
   },
   {
    "duration": 523,
    "start_time": "2022-03-15T04:33:04.431Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-15T04:33:13.329Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-15T04:33:16.452Z"
   },
   {
    "duration": 329,
    "start_time": "2022-03-15T04:34:28.277Z"
   },
   {
    "duration": 75,
    "start_time": "2022-03-15T04:34:30.862Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-15T04:35:24.414Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-15T04:35:37.818Z"
   },
   {
    "duration": 106,
    "start_time": "2022-03-15T04:35:45.153Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-15T04:37:16.743Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-15T04:37:16.749Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-15T04:37:16.776Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-15T04:37:16.791Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-15T04:37:16.804Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-15T04:37:16.812Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-15T04:37:16.823Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-15T04:37:16.840Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-15T04:37:16.854Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-15T04:37:16.863Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-15T04:37:16.880Z"
   },
   {
    "duration": 81,
    "start_time": "2022-03-15T04:37:16.903Z"
   },
   {
    "duration": 115,
    "start_time": "2022-03-15T04:37:16.986Z"
   },
   {
    "duration": 401,
    "start_time": "2022-03-15T04:37:17.102Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-15T04:37:17.505Z"
   },
   {
    "duration": 296,
    "start_time": "2022-03-15T04:37:17.541Z"
   },
   {
    "duration": 116,
    "start_time": "2022-03-15T04:37:17.840Z"
   },
   {
    "duration": 1111,
    "start_time": "2022-03-15T14:53:43.112Z"
   },
   {
    "duration": 39,
    "start_time": "2022-03-15T14:53:44.224Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-15T14:53:44.265Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-15T14:53:44.280Z"
   },
   {
    "duration": 2,
    "start_time": "2022-03-15T14:53:44.289Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-15T14:53:44.293Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-15T14:53:44.301Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-15T14:53:44.305Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-15T14:53:44.320Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-15T14:53:44.328Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-15T14:53:44.342Z"
   },
   {
    "duration": 80,
    "start_time": "2022-03-15T14:53:44.365Z"
   },
   {
    "duration": 109,
    "start_time": "2022-03-15T14:53:44.447Z"
   },
   {
    "duration": 389,
    "start_time": "2022-03-15T14:53:44.558Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-15T14:53:44.949Z"
   },
   {
    "duration": 199,
    "start_time": "2022-03-15T14:53:45.003Z"
   },
   {
    "duration": 113,
    "start_time": "2022-03-15T14:53:45.204Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-15T14:58:00.055Z"
   },
   {
    "duration": 53,
    "start_time": "2022-03-15T14:58:28.260Z"
   },
   {
    "duration": 103,
    "start_time": "2022-03-15T14:58:36.618Z"
   },
   {
    "duration": 73,
    "start_time": "2022-03-15T14:58:47.332Z"
   },
   {
    "duration": 102,
    "start_time": "2022-03-15T14:59:32.900Z"
   },
   {
    "duration": 97,
    "start_time": "2022-03-15T14:59:57.583Z"
   },
   {
    "duration": 48,
    "start_time": "2022-03-15T15:00:09.217Z"
   },
   {
    "duration": 477,
    "start_time": "2022-03-15T15:13:06.782Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-15T15:13:21.408Z"
   },
   {
    "duration": 54,
    "start_time": "2022-03-15T15:13:27.161Z"
   },
   {
    "duration": 53,
    "start_time": "2022-03-15T15:13:34.414Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-15T15:13:39.700Z"
   },
   {
    "duration": 102,
    "start_time": "2022-03-15T15:13:56.292Z"
   },
   {
    "duration": 57,
    "start_time": "2022-03-15T15:14:04.951Z"
   },
   {
    "duration": 200,
    "start_time": "2022-03-15T15:16:28.948Z"
   },
   {
    "duration": 55,
    "start_time": "2022-03-15T15:16:32.967Z"
   },
   {
    "duration": 235,
    "start_time": "2022-03-15T15:18:25.512Z"
   },
   {
    "duration": 1063,
    "start_time": "2022-03-16T02:20:24.723Z"
   },
   {
    "duration": 28736,
    "start_time": "2022-03-16T02:20:34.279Z"
   },
   {
    "duration": 199,
    "start_time": "2022-03-16T02:21:22.853Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-16T02:21:32.135Z"
   },
   {
    "duration": 53,
    "start_time": "2022-03-16T02:21:38.648Z"
   },
   {
    "duration": 95,
    "start_time": "2022-03-16T02:46:51.607Z"
   },
   {
    "duration": 347,
    "start_time": "2022-03-16T02:50:17.931Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-16T02:50:20.261Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-16T02:50:20.929Z"
   },
   {
    "duration": 247,
    "start_time": "2022-03-16T02:50:32.669Z"
   },
   {
    "duration": 388,
    "start_time": "2022-03-16T02:50:50.008Z"
   },
   {
    "duration": 241,
    "start_time": "2022-03-16T02:50:53.625Z"
   },
   {
    "duration": 195,
    "start_time": "2022-03-16T02:50:59.112Z"
   },
   {
    "duration": 53,
    "start_time": "2022-03-16T02:51:03.258Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-16T02:51:23.510Z"
   },
   {
    "duration": 24326,
    "start_time": "2022-03-16T02:51:30.126Z"
   },
   {
    "duration": 514671,
    "start_time": "2022-03-16T03:17:12.077Z"
   },
   {
    "duration": 193,
    "start_time": "2022-03-16T03:32:58.669Z"
   },
   {
    "duration": 1227,
    "start_time": "2022-03-16T03:34:38.529Z"
   },
   {
    "duration": 982,
    "start_time": "2022-03-16T03:36:57.613Z"
   },
   {
    "duration": 191,
    "start_time": "2022-03-16T03:37:23.905Z"
   },
   {
    "duration": 59,
    "start_time": "2022-03-16T03:38:41.148Z"
   },
   {
    "duration": 91,
    "start_time": "2022-03-16T03:39:11.211Z"
   },
   {
    "duration": 328,
    "start_time": "2022-03-16T03:41:12.998Z"
   },
   {
    "duration": 123,
    "start_time": "2022-03-16T03:41:20.278Z"
   },
   {
    "duration": 30474,
    "start_time": "2022-03-16T03:41:36.007Z"
   },
   {
    "duration": 126,
    "start_time": "2022-03-16T03:42:45.354Z"
   },
   {
    "duration": 29233,
    "start_time": "2022-03-16T03:44:32.144Z"
   },
   {
    "duration": 124,
    "start_time": "2022-03-16T03:47:59.570Z"
   },
   {
    "duration": 164,
    "start_time": "2022-03-16T03:48:30.649Z"
   },
   {
    "duration": 1501,
    "start_time": "2022-03-17T00:40:04.472Z"
   },
   {
    "duration": 48,
    "start_time": "2022-03-17T00:40:05.976Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-17T00:40:06.028Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-17T00:40:06.055Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-17T00:40:06.071Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-17T00:40:06.078Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-17T00:40:06.091Z"
   },
   {
    "duration": 59,
    "start_time": "2022-03-17T00:40:06.102Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-17T00:40:06.163Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-17T00:40:06.175Z"
   },
   {
    "duration": 63,
    "start_time": "2022-03-17T00:40:06.202Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-17T00:40:06.268Z"
   },
   {
    "duration": 99,
    "start_time": "2022-03-17T00:40:06.274Z"
   },
   {
    "duration": 175,
    "start_time": "2022-03-17T00:40:06.375Z"
   },
   {
    "duration": 100,
    "start_time": "2022-03-17T00:40:06.552Z"
   },
   {
    "duration": 426,
    "start_time": "2022-03-17T00:40:06.744Z"
   },
   {
    "duration": 365,
    "start_time": "2022-03-17T00:40:07.173Z"
   },
   {
    "duration": 84,
    "start_time": "2022-03-17T00:40:07.543Z"
   },
   {
    "duration": 37214,
    "start_time": "2022-03-17T00:40:07.643Z"
   },
   {
    "duration": 270,
    "start_time": "2022-03-17T00:40:44.859Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-17T00:40:45.131Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-17T00:42:21.861Z"
   },
   {
    "duration": 465,
    "start_time": "2022-03-17T00:42:47.979Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-17T00:43:00.491Z"
   },
   {
    "duration": 255,
    "start_time": "2022-03-17T00:43:03.548Z"
   },
   {
    "duration": 257,
    "start_time": "2022-03-17T01:11:26.980Z"
   },
   {
    "duration": 254,
    "start_time": "2022-03-17T01:11:33.430Z"
   },
   {
    "duration": 256,
    "start_time": "2022-03-17T01:11:43.214Z"
   },
   {
    "duration": 259,
    "start_time": "2022-03-17T01:12:19.053Z"
   },
   {
    "duration": 258,
    "start_time": "2022-03-17T01:41:19.074Z"
   },
   {
    "duration": 261,
    "start_time": "2022-03-17T01:41:29.209Z"
   },
   {
    "duration": 631,
    "start_time": "2022-03-17T01:42:23.880Z"
   },
   {
    "duration": 288,
    "start_time": "2022-03-17T01:42:45.973Z"
   },
   {
    "duration": 281,
    "start_time": "2022-03-17T01:43:30.764Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-17T01:43:56.001Z"
   },
   {
    "duration": 251,
    "start_time": "2022-03-17T01:44:48.520Z"
   },
   {
    "duration": 1487,
    "start_time": "2022-03-17T01:54:07.605Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-17T01:54:09.095Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-17T01:54:09.144Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-17T01:54:09.168Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-17T01:54:09.181Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-17T01:54:09.187Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-17T01:54:09.199Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-17T01:54:09.248Z"
   },
   {
    "duration": 115,
    "start_time": "2022-03-17T01:54:09.273Z"
   },
   {
    "duration": 778,
    "start_time": "2022-03-17T01:54:08.612Z"
   },
   {
    "duration": 778,
    "start_time": "2022-03-17T01:54:08.613Z"
   },
   {
    "duration": 665,
    "start_time": "2022-03-17T01:54:08.728Z"
   },
   {
    "duration": 662,
    "start_time": "2022-03-17T01:54:08.732Z"
   },
   {
    "duration": 663,
    "start_time": "2022-03-17T01:54:08.733Z"
   },
   {
    "duration": 663,
    "start_time": "2022-03-17T01:54:08.734Z"
   },
   {
    "duration": 663,
    "start_time": "2022-03-17T01:54:08.735Z"
   },
   {
    "duration": 663,
    "start_time": "2022-03-17T01:54:08.736Z"
   },
   {
    "duration": 664,
    "start_time": "2022-03-17T01:54:08.737Z"
   },
   {
    "duration": 664,
    "start_time": "2022-03-17T01:54:08.738Z"
   },
   {
    "duration": 664,
    "start_time": "2022-03-17T01:54:08.739Z"
   },
   {
    "duration": 664,
    "start_time": "2022-03-17T01:54:08.740Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-17T01:55:28.568Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-17T01:55:28.591Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-17T01:55:28.607Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-17T01:55:28.637Z"
   },
   {
    "duration": 456,
    "start_time": "2022-03-17T01:55:28.646Z"
   },
   {
    "duration": 777,
    "start_time": "2022-03-17T01:55:28.328Z"
   },
   {
    "duration": 777,
    "start_time": "2022-03-17T01:55:28.329Z"
   },
   {
    "duration": 778,
    "start_time": "2022-03-17T01:55:28.330Z"
   },
   {
    "duration": 777,
    "start_time": "2022-03-17T01:55:28.333Z"
   },
   {
    "duration": 777,
    "start_time": "2022-03-17T01:55:28.334Z"
   },
   {
    "duration": 612,
    "start_time": "2022-03-17T01:55:28.501Z"
   },
   {
    "duration": 612,
    "start_time": "2022-03-17T01:55:28.502Z"
   },
   {
    "duration": 613,
    "start_time": "2022-03-17T01:55:28.503Z"
   },
   {
    "duration": 613,
    "start_time": "2022-03-17T01:55:28.504Z"
   },
   {
    "duration": 358,
    "start_time": "2022-03-17T01:56:29.157Z"
   },
   {
    "duration": 1430,
    "start_time": "2022-03-17T01:56:35.754Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-17T01:56:37.187Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-17T01:56:37.225Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-17T01:56:37.253Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-17T01:56:37.267Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-17T01:56:37.274Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-17T01:56:37.285Z"
   },
   {
    "duration": 65,
    "start_time": "2022-03-17T01:56:37.294Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-17T01:56:37.363Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-17T01:56:37.379Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-17T01:56:37.410Z"
   },
   {
    "duration": 455,
    "start_time": "2022-03-17T01:56:37.444Z"
   },
   {
    "duration": 788,
    "start_time": "2022-03-17T01:56:37.114Z"
   },
   {
    "duration": 779,
    "start_time": "2022-03-17T01:56:37.124Z"
   },
   {
    "duration": 780,
    "start_time": "2022-03-17T01:56:37.125Z"
   },
   {
    "duration": 781,
    "start_time": "2022-03-17T01:56:37.126Z"
   },
   {
    "duration": 777,
    "start_time": "2022-03-17T01:56:37.131Z"
   },
   {
    "duration": 778,
    "start_time": "2022-03-17T01:56:37.132Z"
   },
   {
    "duration": 778,
    "start_time": "2022-03-17T01:56:37.133Z"
   },
   {
    "duration": 779,
    "start_time": "2022-03-17T01:56:37.134Z"
   },
   {
    "duration": 776,
    "start_time": "2022-03-17T01:56:37.138Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-17T01:57:14.871Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-17T01:57:14.894Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-17T01:57:14.911Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-17T01:57:14.946Z"
   },
   {
    "duration": 68,
    "start_time": "2022-03-17T01:57:14.953Z"
   },
   {
    "duration": 157,
    "start_time": "2022-03-17T01:57:15.023Z"
   },
   {
    "duration": 169,
    "start_time": "2022-03-17T01:57:15.182Z"
   },
   {
    "duration": 459,
    "start_time": "2022-03-17T01:57:15.354Z"
   },
   {
    "duration": 310,
    "start_time": "2022-03-17T01:57:15.817Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-17T01:57:16.130Z"
   },
   {
    "duration": 29705,
    "start_time": "2022-03-17T01:57:16.222Z"
   },
   {
    "duration": 277,
    "start_time": "2022-03-17T01:57:45.930Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-17T01:57:46.210Z"
   },
   {
    "duration": 336,
    "start_time": "2022-03-17T01:57:46.259Z"
   },
   {
    "duration": 350,
    "start_time": "2022-03-17T02:04:17.881Z"
   },
   {
    "duration": 67960,
    "start_time": "2022-03-17T02:04:27.338Z"
   },
   {
    "duration": 254,
    "start_time": "2022-03-17T02:27:43.309Z"
   },
   {
    "duration": 64,
    "start_time": "2022-03-18T01:47:03.231Z"
   },
   {
    "duration": 2051,
    "start_time": "2022-03-18T01:47:09.234Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-18T01:47:11.288Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-18T01:47:11.320Z"
   },
   {
    "duration": 39,
    "start_time": "2022-03-18T01:47:11.348Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T01:47:11.389Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-18T01:47:11.396Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-18T01:47:11.409Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-18T01:47:11.418Z"
   },
   {
    "duration": 44,
    "start_time": "2022-03-18T01:47:11.438Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-18T01:47:11.486Z"
   },
   {
    "duration": 33,
    "start_time": "2022-03-18T01:47:11.494Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T01:47:11.529Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-18T01:47:11.536Z"
   },
   {
    "duration": 1047,
    "start_time": "2022-03-18T01:47:11.635Z"
   },
   {
    "duration": 201,
    "start_time": "2022-03-18T01:47:12.685Z"
   },
   {
    "duration": 1208,
    "start_time": "2022-03-18T01:47:12.889Z"
   },
   {
    "duration": 2224,
    "start_time": "2022-03-18T01:47:14.099Z"
   },
   {
    "duration": 428,
    "start_time": "2022-03-18T01:47:16.325Z"
   },
   {
    "duration": 226503,
    "start_time": "2022-03-18T01:47:16.755Z"
   },
   {
    "duration": 303,
    "start_time": "2022-03-18T01:51:03.261Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-18T01:51:03.566Z"
   },
   {
    "duration": 256,
    "start_time": "2022-03-18T01:51:03.658Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-18T01:51:03.918Z"
   },
   {
    "duration": 151,
    "start_time": "2022-03-18T01:52:04.278Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-18T01:52:08.248Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-18T01:52:13.136Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-18T01:52:48.890Z"
   },
   {
    "duration": 31,
    "start_time": "2022-03-18T01:52:48.899Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-18T01:52:48.932Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-18T01:52:48.953Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T01:52:48.990Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-18T01:52:48.997Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-18T01:52:49.031Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-18T01:52:49.048Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-18T01:52:49.075Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-18T01:52:49.089Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-18T01:52:49.110Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-18T01:52:49.147Z"
   },
   {
    "duration": 86,
    "start_time": "2022-03-18T01:52:49.154Z"
   },
   {
    "duration": 1063,
    "start_time": "2022-03-18T01:52:49.244Z"
   },
   {
    "duration": 175,
    "start_time": "2022-03-18T01:52:50.309Z"
   },
   {
    "duration": 1219,
    "start_time": "2022-03-18T01:52:50.487Z"
   },
   {
    "duration": 2221,
    "start_time": "2022-03-18T01:58:34.133Z"
   },
   {
    "duration": 417,
    "start_time": "2022-03-18T01:58:45.992Z"
   },
   {
    "duration": 413434,
    "start_time": "2022-03-18T01:59:21.105Z"
   },
   {
    "duration": 1507,
    "start_time": "2022-03-18T02:09:47.637Z"
   },
   {
    "duration": 411,
    "start_time": "2022-03-18T02:13:23.505Z"
   },
   {
    "duration": 347667,
    "start_time": "2022-03-18T02:13:29.060Z"
   },
   {
    "duration": 310053,
    "start_time": "2022-03-18T02:30:58.418Z"
   },
   {
    "duration": 346938,
    "start_time": "2022-03-18T02:36:09.704Z"
   },
   {
    "duration": 17227,
    "start_time": "2022-03-18T02:42:10.760Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-18T02:46:31.233Z"
   },
   {
    "duration": 277,
    "start_time": "2022-03-18T02:47:03.669Z"
   },
   {
    "duration": 78,
    "start_time": "2022-03-18T02:47:48.828Z"
   },
   {
    "duration": 57736,
    "start_time": "2022-03-18T03:06:55.523Z"
   },
   {
    "duration": 7897,
    "start_time": "2022-03-18T03:07:56.303Z"
   },
   {
    "duration": 92426,
    "start_time": "2022-03-18T03:10:01.612Z"
   },
   {
    "duration": 1174,
    "start_time": "2022-03-18T03:14:01.561Z"
   },
   {
    "duration": 102592,
    "start_time": "2022-03-18T03:14:12.145Z"
   },
   {
    "duration": 232,
    "start_time": "2022-03-18T03:16:26.430Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-18T03:16:39.623Z"
   },
   {
    "duration": 1052,
    "start_time": "2022-03-18T03:18:25.647Z"
   },
   {
    "duration": 90504,
    "start_time": "2022-03-18T03:18:37.656Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-18T03:20:13.674Z"
   },
   {
    "duration": 203,
    "start_time": "2022-03-18T03:20:23.019Z"
   },
   {
    "duration": 191,
    "start_time": "2022-03-18T03:20:42.768Z"
   },
   {
    "duration": 221,
    "start_time": "2022-03-18T03:20:47.233Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-18T03:21:59.407Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-18T03:21:59.418Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-18T03:21:59.447Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-18T03:21:59.471Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T03:21:59.500Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-18T03:21:59.508Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T03:21:59.520Z"
   },
   {
    "duration": 54,
    "start_time": "2022-03-18T03:21:59.528Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-18T03:21:59.585Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-18T03:21:59.600Z"
   },
   {
    "duration": 72,
    "start_time": "2022-03-18T03:21:59.610Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-18T03:21:59.685Z"
   },
   {
    "duration": 113,
    "start_time": "2022-03-18T03:21:59.694Z"
   },
   {
    "duration": 1587,
    "start_time": "2022-03-18T03:21:59.813Z"
   },
   {
    "duration": 188,
    "start_time": "2022-03-18T03:22:01.403Z"
   },
   {
    "duration": 1924,
    "start_time": "2022-03-18T03:22:01.594Z"
   },
   {
    "duration": 1549,
    "start_time": "2022-03-18T03:22:03.520Z"
   },
   {
    "duration": 95321,
    "start_time": "2022-03-18T03:22:05.072Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T03:23:40.395Z"
   },
   {
    "duration": 213,
    "start_time": "2022-03-18T03:23:40.402Z"
   },
   {
    "duration": 47835,
    "start_time": "2022-03-18T03:46:02.986Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-18T03:49:14.962Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T03:49:26.026Z"
   },
   {
    "duration": 186,
    "start_time": "2022-03-18T03:49:41.045Z"
   },
   {
    "duration": 2264,
    "start_time": "2022-03-18T04:16:48.594Z"
   },
   {
    "duration": 202927,
    "start_time": "2022-03-18T04:17:41.664Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T04:21:48.386Z"
   },
   {
    "duration": 193,
    "start_time": "2022-03-18T04:21:51.774Z"
   },
   {
    "duration": 101466,
    "start_time": "2022-03-18T04:23:27.883Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-18T04:25:14.477Z"
   },
   {
    "duration": 185,
    "start_time": "2022-03-18T04:25:17.987Z"
   },
   {
    "duration": 141,
    "start_time": "2022-03-18T04:27:08.831Z"
   },
   {
    "duration": 7412,
    "start_time": "2022-03-18T04:30:04.279Z"
   },
   {
    "duration": 172663,
    "start_time": "2022-03-18T04:30:14.688Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-18T04:46:08.194Z"
   },
   {
    "duration": 180,
    "start_time": "2022-03-18T04:46:36.368Z"
   },
   {
    "duration": 2399,
    "start_time": "2022-03-19T00:58:58.866Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-19T00:59:01.269Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-19T00:59:01.321Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-19T00:59:01.349Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T00:59:01.372Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-19T00:59:01.380Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-19T00:59:01.394Z"
   },
   {
    "duration": 50,
    "start_time": "2022-03-19T00:59:01.403Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-19T00:59:01.456Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-19T00:59:01.473Z"
   },
   {
    "duration": 76,
    "start_time": "2022-03-19T00:59:01.484Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T00:59:01.563Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-19T00:59:01.571Z"
   },
   {
    "duration": 1144,
    "start_time": "2022-03-19T00:59:01.673Z"
   },
   {
    "duration": 223,
    "start_time": "2022-03-19T00:59:02.819Z"
   },
   {
    "duration": 1275,
    "start_time": "2022-03-19T00:59:03.044Z"
   },
   {
    "duration": 2377,
    "start_time": "2022-03-19T00:59:04.321Z"
   },
   {
    "duration": 436,
    "start_time": "2022-03-19T00:59:06.700Z"
   },
   {
    "duration": 17669,
    "start_time": "2022-03-19T00:59:07.142Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-19T00:59:24.813Z"
   },
   {
    "duration": 297,
    "start_time": "2022-03-19T00:59:24.847Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-19T00:59:25.147Z"
   },
   {
    "duration": 187,
    "start_time": "2022-03-19T00:59:25.245Z"
   },
   {
    "duration": 2321,
    "start_time": "2022-03-19T00:59:25.435Z"
   },
   {
    "duration": 210413,
    "start_time": "2022-03-19T00:59:27.759Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-19T01:02:58.174Z"
   },
   {
    "duration": 202,
    "start_time": "2022-03-19T01:02:58.181Z"
   },
   {
    "duration": 105130,
    "start_time": "2022-03-19T01:02:58.385Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-19T01:04:43.517Z"
   },
   {
    "duration": 277,
    "start_time": "2022-03-19T01:04:43.524Z"
   },
   {
    "duration": 179788,
    "start_time": "2022-03-19T01:04:43.802Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-19T01:07:43.592Z"
   },
   {
    "duration": 199,
    "start_time": "2022-03-19T01:07:43.599Z"
   },
   {
    "duration": 362712,
    "start_time": "2022-03-19T01:15:18.523Z"
   },
   {
    "duration": 17696,
    "start_time": "2022-03-19T01:22:19.022Z"
   },
   {
    "duration": 14838,
    "start_time": "2022-03-19T01:26:41.549Z"
   },
   {
    "duration": 15155,
    "start_time": "2022-03-19T01:27:19.466Z"
   },
   {
    "duration": 15191,
    "start_time": "2022-03-19T01:28:14.125Z"
   },
   {
    "duration": 2025,
    "start_time": "2022-03-19T01:28:54.573Z"
   },
   {
    "duration": 37,
    "start_time": "2022-03-19T01:28:56.600Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-19T01:28:56.640Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-19T01:28:56.668Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T01:28:56.689Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-19T01:28:56.697Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T01:28:56.742Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-19T01:28:56.750Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-19T01:28:56.771Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-19T01:28:56.788Z"
   },
   {
    "duration": 80,
    "start_time": "2022-03-19T01:28:56.798Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-19T01:28:56.881Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-19T01:28:56.888Z"
   },
   {
    "duration": 1124,
    "start_time": "2022-03-19T01:28:56.981Z"
   },
   {
    "duration": 145,
    "start_time": "2022-03-19T01:28:58.108Z"
   },
   {
    "duration": 1298,
    "start_time": "2022-03-19T01:28:58.344Z"
   },
   {
    "duration": 2425,
    "start_time": "2022-03-19T01:28:59.644Z"
   },
   {
    "duration": 443,
    "start_time": "2022-03-19T01:29:02.071Z"
   },
   {
    "duration": 17909,
    "start_time": "2022-03-19T01:29:02.517Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-19T01:29:20.428Z"
   },
   {
    "duration": 306,
    "start_time": "2022-03-19T01:29:20.454Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-19T01:29:20.762Z"
   },
   {
    "duration": 205,
    "start_time": "2022-03-19T01:29:20.855Z"
   },
   {
    "duration": 2340,
    "start_time": "2022-03-19T01:29:21.063Z"
   },
   {
    "duration": 210286,
    "start_time": "2022-03-19T01:29:23.405Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T01:32:53.693Z"
   },
   {
    "duration": 201,
    "start_time": "2022-03-19T01:32:53.702Z"
   },
   {
    "duration": 104518,
    "start_time": "2022-03-19T01:32:53.907Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-19T01:34:38.427Z"
   },
   {
    "duration": 196,
    "start_time": "2022-03-19T01:34:38.443Z"
   },
   {
    "duration": 179927,
    "start_time": "2022-03-19T01:34:38.643Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T01:37:38.572Z"
   },
   {
    "duration": 204,
    "start_time": "2022-03-19T01:37:38.580Z"
   },
   {
    "duration": 2180,
    "start_time": "2022-03-19T01:38:22.615Z"
   },
   {
    "duration": 2176,
    "start_time": "2022-03-19T01:50:15.773Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-19T01:50:53.763Z"
   },
   {
    "duration": 148,
    "start_time": "2022-03-19T01:51:12.174Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-19T01:51:37.610Z"
   },
   {
    "duration": 18055,
    "start_time": "2022-03-19T01:53:17.452Z"
   },
   {
    "duration": 15012,
    "start_time": "2022-03-19T01:53:42.766Z"
   },
   {
    "duration": 75,
    "start_time": "2022-03-19T01:58:11.921Z"
   },
   {
    "duration": 17012,
    "start_time": "2022-03-19T01:59:54.332Z"
   },
   {
    "duration": 17856,
    "start_time": "2022-03-19T02:00:49.857Z"
   },
   {
    "duration": 18275,
    "start_time": "2022-03-19T02:03:09.192Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-19T02:24:25.053Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-19T02:24:25.063Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-19T02:24:25.099Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-19T02:24:25.144Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-19T02:24:25.167Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-19T02:24:25.173Z"
   },
   {
    "duration": 61,
    "start_time": "2022-03-19T02:24:25.183Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-19T02:24:25.247Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-19T02:24:25.264Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-19T02:24:25.283Z"
   },
   {
    "duration": 92,
    "start_time": "2022-03-19T02:24:25.292Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T02:24:25.386Z"
   },
   {
    "duration": 104,
    "start_time": "2022-03-19T02:24:25.394Z"
   },
   {
    "duration": 1132,
    "start_time": "2022-03-19T02:24:25.501Z"
   },
   {
    "duration": 121,
    "start_time": "2022-03-19T02:24:26.635Z"
   },
   {
    "duration": 1303,
    "start_time": "2022-03-19T02:24:26.844Z"
   },
   {
    "duration": 2453,
    "start_time": "2022-03-19T02:24:28.150Z"
   },
   {
    "duration": 465,
    "start_time": "2022-03-19T02:24:30.606Z"
   },
   {
    "duration": 18224,
    "start_time": "2022-03-19T02:24:31.074Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-19T02:24:49.300Z"
   },
   {
    "duration": 341,
    "start_time": "2022-03-19T02:24:49.320Z"
   },
   {
    "duration": 128,
    "start_time": "2022-03-19T02:24:49.663Z"
   },
   {
    "duration": 293,
    "start_time": "2022-03-19T02:24:49.793Z"
   },
   {
    "duration": 3321,
    "start_time": "2022-03-19T02:24:50.089Z"
   },
   {
    "duration": 239224,
    "start_time": "2022-03-19T02:24:53.413Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-19T02:28:52.643Z"
   },
   {
    "duration": 211,
    "start_time": "2022-03-19T02:28:52.650Z"
   },
   {
    "duration": 109368,
    "start_time": "2022-03-19T02:28:52.865Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-19T02:30:42.236Z"
   },
   {
    "duration": 223,
    "start_time": "2022-03-19T02:30:42.248Z"
   },
   {
    "duration": 188347,
    "start_time": "2022-03-19T02:30:42.473Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-19T02:33:50.822Z"
   },
   {
    "duration": 206,
    "start_time": "2022-03-19T02:33:50.842Z"
   },
   {
    "duration": 2194,
    "start_time": "2022-03-19T02:33:51.050Z"
   },
   {
    "duration": 2205,
    "start_time": "2022-03-19T02:33:53.247Z"
   },
   {
    "duration": 2318,
    "start_time": "2022-03-19T02:33:55.454Z"
   },
   {
    "duration": 1741,
    "start_time": "2022-03-26T04:04:53.295Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "366.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
